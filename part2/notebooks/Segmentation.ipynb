{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diskcache import FanoutCache, Disk\n",
    "from diskcache.core import io, MODE_BINARY\n",
    "from io import BytesIO\n",
    "import gzip\n",
    "\n",
    "class GzipDisk(Disk):\n",
    "    def store(self, value, read, key=None):\n",
    "        \"\"\"\n",
    "        Override from base class diskcache.Disk.\n",
    "        Chunking is due to needing to work on pythons < 2.7.13:\n",
    "        - Issue #27130: In the \"zlib\" module, fix handling of large buffers\n",
    "          (typically 2 or 4 GiB).  Previously, inputs were limited to 2 GiB, and\n",
    "          compression and decompression operations did not properly handle results of\n",
    "          2 or 4 GiB.\n",
    "        :param value: value to convert\n",
    "        :param bool read: True when value is file-like object\n",
    "        :return: (size, mode, filename, value) tuple for Cache table\n",
    "        \"\"\"\n",
    "        # pylint: disable=unidiomatic-typecheck\n",
    "        if type(value) is BytesIO:\n",
    "            if read:\n",
    "                value = value.read()\n",
    "                read = False\n",
    "\n",
    "            str_io = BytesIO()\n",
    "            gz_file = gzip.GzipFile(mode='wb', compresslevel=1, fileobj=str_io)\n",
    "\n",
    "            for offset in range(0, len(value), 2**30):\n",
    "                gz_file.write(value[offset:offset+2**30])\n",
    "            gz_file.close()\n",
    "\n",
    "            value = str_io.getvalue()\n",
    "\n",
    "        return super(GzipDisk, self).store(value, read)\n",
    "\n",
    "\n",
    "    def fetch(self, mode, filename, value, read):\n",
    "        \"\"\"\n",
    "        Override from base class diskcache.Disk.\n",
    "        Chunking is due to needing to work on pythons < 2.7.13:\n",
    "        - Issue #27130: In the \"zlib\" module, fix handling of large buffers\n",
    "          (typically 2 or 4 GiB).  Previously, inputs were limited to 2 GiB, and\n",
    "          compression and decompression operations did not properly handle results of\n",
    "          2 or 4 GiB.\n",
    "        :param int mode: value mode raw, binary, text, or pickle\n",
    "        :param str filename: filename of corresponding value\n",
    "        :param value: database value\n",
    "        :param bool read: when True, return an open file handle\n",
    "        :return: corresponding Python value\n",
    "        \"\"\"\n",
    "        value = super(GzipDisk, self).fetch(mode, filename, value, read)\n",
    "\n",
    "        if mode == MODE_BINARY:\n",
    "            str_io = BytesIO(value)\n",
    "            gz_file = gzip.GzipFile(mode='rb', fileobj=str_io)\n",
    "            read_csio = BytesIO()\n",
    "\n",
    "            while True:\n",
    "                uncompressed_data = gz_file.read(2**30)\n",
    "                if uncompressed_data:\n",
    "                    read_csio.write(uncompressed_data)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            value = read_csio.getvalue()\n",
    "\n",
    "        return value\n",
    "\n",
    "\n",
    "def getCache(scope_str):\n",
    "    return FanoutCache('data-unversioned/cache/' + scope_str,\n",
    "                       disk=GzipDisk,\n",
    "                       shards=64,\n",
    "                       timeout=1,\n",
    "                       size_limit=3e11,\n",
    "                       # disk_min_file_size=2**20,\n",
    "                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "IrcTuple = collections.namedtuple('IrcTuple', ['index', 'row', 'col'])\n",
    "XyzTuple = collections.namedtuple('XyzTuple', ['x', 'y', 'z'])\n",
    "\n",
    "def xyz2irc(coord_xyz, origin_xyz, vxSize_xyz, direction_a):\n",
    "    origin_a = np.array(origin_xyz)\n",
    "    vxSize_a = np.array(vxSize_xyz)\n",
    "    coord_a = np.array(coord_xyz)\n",
    "    cri_a = ((coord_a - origin_a) @ np.linalg.inv(direction_a)) / vxSize_a\n",
    "    cri_a = np.round(cri_a)\n",
    "    return IrcTuple(int(cri_a[2]), int(cri_a[1]), int(cri_a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerateWithEstimate(\n",
    "        iter,\n",
    "        desc_str,\n",
    "        start_ndx=0,\n",
    "        print_ndx=4,\n",
    "        backoff=None,\n",
    "        iter_len=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    In terms of behavior, `enumerateWithEstimate` is almost identical\n",
    "    to the standard `enumerate` (the differences are things like how\n",
    "    our function returns a generator, while `enumerate` returns a\n",
    "    specialized `<enumerate object at 0x...>`).\n",
    "    However, the side effects (logging, specifically) are what make the\n",
    "    function interesting.\n",
    "    :param iter: `iter` is the iterable that will be passed into\n",
    "        `enumerate`. Required.\n",
    "    :param desc_str: This is a human-readable string that describes\n",
    "        what the loop is doing. The value is arbitrary, but should be\n",
    "        kept reasonably short. Things like `\"epoch 4 training\"` or\n",
    "        `\"deleting temp files\"` or similar would all make sense.\n",
    "    :param start_ndx: This parameter defines how many iterations of the\n",
    "        loop should be skipped before timing actually starts. Skipping\n",
    "        a few iterations can be useful if there are startup costs like\n",
    "        caching that are only paid early on, resulting in a skewed\n",
    "        average when those early iterations dominate the average time\n",
    "        per iteration.\n",
    "        NOTE: Using `start_ndx` to skip some iterations makes the time\n",
    "        spent performing those iterations not be included in the\n",
    "        displayed duration. Please account for this if you use the\n",
    "        displayed duration for anything formal.\n",
    "        This parameter defaults to `0`.\n",
    "    :param print_ndx: determines which loop interation that the timing\n",
    "        logging will start on. The intent is that we don't start\n",
    "        logging until we've given the loop a few iterations to let the\n",
    "        average time-per-iteration a chance to stablize a bit. We\n",
    "        require that `print_ndx` not be less than `start_ndx` times\n",
    "        `backoff`, since `start_ndx` greater than `0` implies that the\n",
    "        early N iterations are unstable from a timing perspective.\n",
    "        `print_ndx` defaults to `4`.\n",
    "    :param backoff: This is used to how many iterations to skip before\n",
    "        logging again. Frequent logging is less interesting later on,\n",
    "        so by default we double the gap between logging messages each\n",
    "        time after the first.\n",
    "        `backoff` defaults to `2` unless iter_len is > 1000, in which\n",
    "        case it defaults to `4`.\n",
    "    :param iter_len: Since we need to know the number of items to\n",
    "        estimate when the loop will finish, that can be provided by\n",
    "        passing in a value for `iter_len`. If a value isn't provided,\n",
    "        then it will be set by using the value of `len(iter)`.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if iter_len is None:\n",
    "        iter_len = len(iter)\n",
    "\n",
    "    if backoff is None:\n",
    "        backoff = 2\n",
    "        while backoff ** 7 < iter_len:\n",
    "            backoff *= 2\n",
    "\n",
    "    assert backoff >= 2\n",
    "    while print_ndx < start_ndx * backoff:\n",
    "        print_ndx *= backoff\n",
    "\n",
    "    log.warning(\"{} ----/{}, starting\".format(\n",
    "        desc_str,\n",
    "        iter_len,\n",
    "    ))\n",
    "    start_ts = time.time()\n",
    "    for (current_ndx, item) in enumerate(iter):\n",
    "        yield (current_ndx, item)\n",
    "        if current_ndx == print_ndx:\n",
    "            # ... <1>\n",
    "            duration_sec = ((time.time() - start_ts)\n",
    "                            / (current_ndx - start_ndx + 1)\n",
    "                            * (iter_len-start_ndx)\n",
    "                            )\n",
    "\n",
    "            done_dt = datetime.datetime.fromtimestamp(start_ts + duration_sec)\n",
    "            done_td = datetime.timedelta(seconds=duration_sec)\n",
    "\n",
    "            log.info(\"{} {:-4}/{}, done at {}, {}\".format(\n",
    "                desc_str,\n",
    "                current_ndx,\n",
    "                iter_len,\n",
    "                str(done_dt).rsplit('.', 1)[0],\n",
    "                str(done_td).rsplit('.', 1)[0],\n",
    "            ))\n",
    "\n",
    "            print_ndx *= backoff\n",
    "\n",
    "        if current_ndx + 1 == start_ndx:\n",
    "            start_ts = time.time()\n",
    "\n",
    "    log.warning(\"{} ----/{}, done at {}\".format(\n",
    "        desc_str,\n",
    "        iter_len,\n",
    "        str(datetime.datetime.now()).rsplit('.', 1)[0],\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import functools\n",
    "\n",
    "class Luna2dSegmentationDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 val_stride=0,\n",
    "                 isValSet_bool=None,\n",
    "                 series_uid=None,\n",
    "                 contextSlices_count=3,\n",
    "                 fullCt_bool=False,\n",
    "            ):\n",
    "        self.contextSlices_count = contextSlices_count\n",
    "        self.fullCt_bool = fullCt_bool\n",
    "\n",
    "        if series_uid:\n",
    "            self.series_list = [series_uid]\n",
    "        else:\n",
    "            self.series_list = sorted(getCandidateInfoDict().keys())\n",
    "\n",
    "        if isValSet_bool:\n",
    "            assert val_stride > 0, val_stride\n",
    "            self.series_list = self.series_list[::val_stride]\n",
    "            assert self.series_list\n",
    "        elif val_stride > 0:\n",
    "            del self.series_list[::val_stride]\n",
    "            assert self.series_list\n",
    "\n",
    "        self.sample_list = []\n",
    "        for series_uid in self.series_list:\n",
    "            index_count, positive_indexes = getCtSampleSize(series_uid)\n",
    "\n",
    "            if self.fullCt_bool:\n",
    "                self.sample_list += [(series_uid, slice_ndx)\n",
    "                                     for slice_ndx in range(index_count)]\n",
    "            else:\n",
    "                self.sample_list += [(series_uid, slice_ndx)\n",
    "                                     for slice_ndx in positive_indexes]\n",
    "\n",
    "        self.candidateInfo_list = getCandidateInfoList()\n",
    "\n",
    "        series_set = set(self.series_list)\n",
    "        self.candidateInfo_list = [cit for cit in self.candidateInfo_list\n",
    "                                   if cit.series_uid in series_set]\n",
    "\n",
    "        self.pos_list = [nt for nt in self.candidateInfo_list\n",
    "                            if nt.isNodule_bool]\n",
    "\n",
    "        log.info(\"{!r}: {} {} series, {} slices, {} nodules\".format(\n",
    "            self,\n",
    "            len(self.series_list),\n",
    "            {None: 'general', True: 'validation', False: 'training'}[isValSet_bool],\n",
    "            len(self.sample_list),\n",
    "            len(self.pos_list),\n",
    "        ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "\n",
    "    def __getitem__(self, ndx):\n",
    "        series_uid, slice_ndx = self.sample_list[ndx % len(self.sample_list)]\n",
    "        return self.getitem_fullSlice(series_uid, slice_ndx)\n",
    "\n",
    "    def getitem_fullSlice(self, series_uid, slice_ndx):\n",
    "        ct = getCt(series_uid)\n",
    "        ct_t = torch.zeros((self.contextSlices_count * 2 + 1, 512, 512))\n",
    "\n",
    "        start_ndx = slice_ndx - self.contextSlices_count\n",
    "        end_ndx = slice_ndx + self.contextSlices_count + 1\n",
    "        for i, context_ndx in enumerate(range(start_ndx, end_ndx)):\n",
    "            context_ndx = max(context_ndx, 0)\n",
    "            context_ndx = min(context_ndx, ct.hu_a.shape[0] - 1)\n",
    "            ct_t[i] = torch.from_numpy(ct.hu_a[context_ndx].astype(np.float32))\n",
    "\n",
    "        # CTs are natively expressed in https://en.wikipedia.org/wiki/Hounsfield_scale\n",
    "        # HU are scaled oddly, with 0 g/cc (air, approximately) being -1000 and 1 g/cc (water) being 0.\n",
    "        # The lower bound gets rid of negative density stuff used to indicate out-of-FOV\n",
    "        # The upper bound nukes any weird hotspots and clamps bone down\n",
    "        ct_t.clamp_(-1000, 1000)\n",
    "\n",
    "        pos_t = torch.from_numpy(ct.positive_mask[slice_ndx]).unsqueeze(0)\n",
    "\n",
    "        return ct_t, pos_t, ct.series_uid, slice_ndx\n",
    "\n",
    "\n",
    "class TrainingLuna2dSegmentationDataset(Luna2dSegmentationDataset):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.ratio_int = 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return 300000\n",
    "\n",
    "    def shuffleSamples(self):\n",
    "        random.shuffle(self.candidateInfo_list)\n",
    "        random.shuffle(self.pos_list)\n",
    "\n",
    "    def __getitem__(self, ndx):\n",
    "        candidateInfo_tup = self.pos_list[ndx % len(self.pos_list)]\n",
    "        return self.getitem_trainingCrop(candidateInfo_tup)\n",
    "\n",
    "    def getitem_trainingCrop(self, candidateInfo_tup):\n",
    "        ct_a, pos_a, center_irc = getCtRawCandidate(\n",
    "            candidateInfo_tup.series_uid,\n",
    "            candidateInfo_tup.center_xyz,\n",
    "            (7, 96, 96),\n",
    "        )\n",
    "        pos_a = pos_a[3:4]\n",
    "\n",
    "        row_offset = random.randrange(0,32)\n",
    "        col_offset = random.randrange(0,32)\n",
    "        ct_t = torch.from_numpy(ct_a[:, row_offset:row_offset+64,\n",
    "                                     col_offset:col_offset+64]).to(torch.float32)\n",
    "        pos_t = torch.from_numpy(pos_a[:, row_offset:row_offset+64,\n",
    "                                       col_offset:col_offset+64]).to(torch.long)\n",
    "\n",
    "        slice_ndx = center_irc.index\n",
    "\n",
    "        return ct_t, pos_t, candidateInfo_tup.series_uid, slice_ndx\n",
    "\n",
    "    \n",
    "@functools.lru_cache(1, typed=True)\n",
    "def getCt(series_uid):\n",
    "    return Ct(series_uid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LunaTrainingApp\n",
    "\n",
    "class LunaTrainingApp:\n",
    "    def __init__(self, sys_argv=None):\n",
    "        if sys_argv is None:\n",
    "            sys_argv = sys.argv[1:]\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--batch-size',\n",
    "            help='Batch size to use for training',\n",
    "            default=32,\n",
    "            type=int,\n",
    "        )\n",
    "        parser.add_argument('--num-workers',\n",
    "            help='Number of worker processes for background data loading',\n",
    "            default=8,\n",
    "            type=int,\n",
    "        )\n",
    "        parser.add_argument('--epochs',\n",
    "            help='Number of epochs to train for',\n",
    "            default=1,\n",
    "            type=int,\n",
    "        )\n",
    "        parser.add_argument('--balanced',\n",
    "            help=\"Balance the training data to half positive, half negative.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augmented',\n",
    "            help=\"Augment the training data.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-flip',\n",
    "            help=\"Augment the training data by randomly flipping the data left-right, up-down, and front-back.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-offset',\n",
    "            help=\"Augment the training data by randomly offsetting the data slightly along the X and Y axes.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-scale',\n",
    "            help=\"Augment the training data by randomly increasing or decreasing the size of the candidate.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-rotate',\n",
    "            help=\"Augment the training data by randomly rotating the data around the head-foot axis.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-noise',\n",
    "            help=\"Augment the training data by randomly adding noise to the data.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "\n",
    "        parser.add_argument('--tb-prefix',\n",
    "            default='p2ch12',\n",
    "            help=\"Data prefix to use for Tensorboard run. Defaults to chapter.\",\n",
    "        )\n",
    "        parser.add_argument('comment',\n",
    "            help=\"Comment suffix for Tensorboard run.\",\n",
    "            nargs='?',\n",
    "            default='dlwpt',\n",
    "        )\n",
    "\n",
    "        self.cli_args = parser.parse_args(sys_argv)\n",
    "        self.time_str = datetime.datetime.now().strftime('%Y-%m-%d_%H.%M.%S')\n",
    "\n",
    "        self.trn_writer = None\n",
    "        self.val_writer = None\n",
    "        self.totalTrainingSamples_count = 0\n",
    "\n",
    "        self.augmentation_dict = {}\n",
    "        if self.cli_args.augmented or self.cli_args.augment_flip:\n",
    "            self.augmentation_dict['flip'] = True\n",
    "        if self.cli_args.augmented or self.cli_args.augment_offset:\n",
    "            self.augmentation_dict['offset'] = 0.1\n",
    "        if self.cli_args.augmented or self.cli_args.augment_scale:\n",
    "            self.augmentation_dict['scale'] = 0.2\n",
    "        if self.cli_args.augmented or self.cli_args.augment_rotate:\n",
    "            self.augmentation_dict['rotate'] = True\n",
    "        if self.cli_args.augmented or self.cli_args.augment_noise:\n",
    "            self.augmentation_dict['noise'] = 25.0\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "\n",
    "        self.model = self.initModel()\n",
    "        self.optimizer = self.initOptimizer()\n",
    "\n",
    "\n",
    "    def initModel(self):\n",
    "        model = LunaModel()\n",
    "        if self.use_cuda:\n",
    "            log.info(\"Using CUDA; {} devices.\".format(torch.cuda.device_count()))\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                model = nn.DataParallel(model)\n",
    "            model = model.to(self.device)\n",
    "        return model\n",
    "\n",
    "    def initOptimizer(self):\n",
    "        return SGD(self.model.parameters(), lr=0.001, momentum=0.99)\n",
    "        # return Adam(self.model.parameters())\n",
    "\n",
    "    def initTrainDl(self):\n",
    "        train_ds = LunaDataset(\n",
    "            val_stride=10,\n",
    "            isValSet_bool=False,\n",
    "            ratio_int=int(self.cli_args.balanced),\n",
    "            augmentation_dict=self.augmentation_dict,\n",
    "        )\n",
    "\n",
    "        batch_size = self.cli_args.batch_size\n",
    "        if self.use_cuda:\n",
    "            batch_size *= torch.cuda.device_count()\n",
    "\n",
    "        train_dl = DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=self.cli_args.num_workers,\n",
    "            pin_memory=self.use_cuda,\n",
    "        )\n",
    "\n",
    "        return train_dl\n",
    "\n",
    "    def initValDl(self):\n",
    "        val_ds = LunaDataset(\n",
    "            val_stride=10,\n",
    "            isValSet_bool=True,\n",
    "        )\n",
    "\n",
    "        batch_size = self.cli_args.batch_size\n",
    "        if self.use_cuda:\n",
    "            batch_size *= torch.cuda.device_count()\n",
    "\n",
    "        val_dl = DataLoader(\n",
    "            val_ds,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=self.cli_args.num_workers,\n",
    "            pin_memory=self.use_cuda,\n",
    "        )\n",
    "\n",
    "        return val_dl\n",
    "\n",
    "    def initTensorboardWriters(self):\n",
    "        if self.trn_writer is None:\n",
    "            log_dir = os.path.join('runs', self.cli_args.tb_prefix, self.time_str)\n",
    "\n",
    "            self.trn_writer = SummaryWriter(\n",
    "                log_dir=log_dir + '-trn_cls-' + self.cli_args.comment)\n",
    "            self.val_writer = SummaryWriter(\n",
    "                log_dir=log_dir + '-val_cls-' + self.cli_args.comment)\n",
    "\n",
    "\n",
    "    def main(self):\n",
    "        log.info(\"Starting {}, {}\".format(type(self).__name__, self.cli_args))\n",
    "\n",
    "        train_dl = self.initTrainDl()\n",
    "        val_dl = self.initValDl()\n",
    "\n",
    "        for epoch_ndx in range(1, self.cli_args.epochs + 1):\n",
    "\n",
    "            log.info(\"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "                epoch_ndx,\n",
    "                self.cli_args.epochs,\n",
    "                len(train_dl),\n",
    "                len(val_dl),\n",
    "                self.cli_args.batch_size,\n",
    "                (torch.cuda.device_count() if self.use_cuda else 1),\n",
    "            ))\n",
    "\n",
    "            trnMetrics_t = self.doTraining(epoch_ndx, train_dl)\n",
    "            self.logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n",
    "\n",
    "            valMetrics_t = self.doValidation(epoch_ndx, val_dl)\n",
    "            self.logMetrics(epoch_ndx, 'val', valMetrics_t)\n",
    "\n",
    "        if hasattr(self, 'trn_writer'):\n",
    "            self.trn_writer.close()\n",
    "            self.val_writer.close()\n",
    "\n",
    "\n",
    "    def doTraining(self, epoch_ndx, train_dl):\n",
    "        self.model.train()\n",
    "        train_dl.dataset.shuffleSamples()\n",
    "        trnMetrics_g = torch.zeros(\n",
    "            METRICS_SIZE,\n",
    "            len(train_dl.dataset),\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            train_dl,\n",
    "            \"E{} Training\".format(epoch_ndx),\n",
    "            start_ndx=train_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, batch_tup in batch_iter:\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            loss_var = self.computeBatchLoss(\n",
    "                batch_ndx,\n",
    "                batch_tup,\n",
    "                train_dl.batch_size,\n",
    "                trnMetrics_g,\n",
    "            )\n",
    "\n",
    "            loss_var.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        self.totalTrainingSamples_count += len(train_dl.dataset)\n",
    "\n",
    "        return trnMetrics_g.to('cpu')\n",
    "\n",
    "\n",
    "    def doValidation(self, epoch_ndx, val_dl):\n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            valMetrics_g = torch.zeros(\n",
    "                METRICS_SIZE,\n",
    "                len(val_dl.dataset),\n",
    "                device=self.device,\n",
    "            )\n",
    "\n",
    "            batch_iter = enumerateWithEstimate(\n",
    "                val_dl,\n",
    "                \"E{} Validation \".format(epoch_ndx),\n",
    "                start_ndx=val_dl.num_workers,\n",
    "            )\n",
    "            for batch_ndx, batch_tup in batch_iter:\n",
    "                self.computeBatchLoss(\n",
    "                    batch_ndx,\n",
    "                    batch_tup,\n",
    "                    val_dl.batch_size,\n",
    "                    valMetrics_g,\n",
    "                )\n",
    "\n",
    "        return valMetrics_g.to('cpu')\n",
    "\n",
    "\n",
    "\n",
    "    def computeBatchLoss(self, batch_ndx, batch_tup, batch_size, metrics_g):\n",
    "        input_t, label_t, _series_list, _center_list = batch_tup\n",
    "\n",
    "        input_g = input_t.to(self.device, non_blocking=True)\n",
    "        label_g = label_t.to(self.device, non_blocking=True)\n",
    "\n",
    "        logits_g, probability_g = self.model(input_g)\n",
    "\n",
    "        loss_func = nn.CrossEntropyLoss(reduction='none')\n",
    "        loss_g = loss_func(\n",
    "            logits_g,\n",
    "            label_g[:,1],\n",
    "        )\n",
    "        start_ndx = batch_ndx * batch_size\n",
    "        end_ndx = start_ndx + label_t.size(0)\n",
    "\n",
    "        metrics_g[METRICS_LABEL_NDX, start_ndx:end_ndx] = label_g[:,1]\n",
    "        metrics_g[METRICS_PRED_NDX, start_ndx:end_ndx] = probability_g[:,1]\n",
    "        metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = loss_g\n",
    "\n",
    "        return loss_g.mean()\n",
    "\n",
    "\n",
    "    def logMetrics(\n",
    "            self,\n",
    "            epoch_ndx,\n",
    "            mode_str,\n",
    "            metrics_t,\n",
    "            classificationThreshold=0.5,\n",
    "    ):\n",
    "        self.initTensorboardWriters()\n",
    "        log.info(\"E{} {}\".format(\n",
    "            epoch_ndx,\n",
    "            type(self).__name__,\n",
    "        ))\n",
    "\n",
    "        negLabel_mask = metrics_t[METRICS_LABEL_NDX] <= classificationThreshold\n",
    "        negPred_mask = metrics_t[METRICS_PRED_NDX] <= classificationThreshold\n",
    "\n",
    "        posLabel_mask = ~negLabel_mask\n",
    "        posPred_mask = ~negPred_mask\n",
    "\n",
    "        neg_count = int(negLabel_mask.sum())\n",
    "        pos_count = int(posLabel_mask.sum())\n",
    "\n",
    "        trueNeg_count = neg_correct = int((negLabel_mask & negPred_mask).sum())\n",
    "        truePos_count = pos_correct = int((posLabel_mask & posPred_mask).sum())\n",
    "\n",
    "        falsePos_count = neg_count - neg_correct\n",
    "        falseNeg_count = pos_count - pos_correct\n",
    "\n",
    "        metrics_dict = {}\n",
    "        metrics_dict['loss/all'] = metrics_t[METRICS_LOSS_NDX].mean()\n",
    "        metrics_dict['loss/neg'] = metrics_t[METRICS_LOSS_NDX, negLabel_mask].mean()\n",
    "        metrics_dict['loss/pos'] = metrics_t[METRICS_LOSS_NDX, posLabel_mask].mean()\n",
    "\n",
    "        metrics_dict['correct/all'] = (pos_correct + neg_correct) / metrics_t.shape[1] * 100\n",
    "        metrics_dict['correct/neg'] = (neg_correct) / neg_count * 100\n",
    "        metrics_dict['correct/pos'] = (pos_correct) / pos_count * 100\n",
    "\n",
    "        precision = metrics_dict['pr/precision'] = \\\n",
    "            truePos_count / np.float32(truePos_count + falsePos_count)\n",
    "        recall    = metrics_dict['pr/recall'] = \\\n",
    "            truePos_count / np.float32(truePos_count + falseNeg_count)\n",
    "\n",
    "        metrics_dict['pr/f1_score'] = \\\n",
    "            2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "        log.info(\n",
    "            (\"E{} {:8} {loss/all:.4f} loss, \"\n",
    "                 + \"{correct/all:-5.1f}% correct, \"\n",
    "                 + \"{pr/precision:.4f} precision, \"\n",
    "                 + \"{pr/recall:.4f} recall, \"\n",
    "                 + \"{pr/f1_score:.4f} f1 score\"\n",
    "            ).format(\n",
    "                epoch_ndx,\n",
    "                mode_str,\n",
    "                **metrics_dict,\n",
    "            )\n",
    "        )\n",
    "        log.info(\n",
    "            (\"E{} {:8} {loss/neg:.4f} loss, \"\n",
    "                 + \"{correct/neg:-5.1f}% correct ({neg_correct:} of {neg_count:})\"\n",
    "            ).format(\n",
    "                epoch_ndx,\n",
    "                mode_str + '_neg',\n",
    "                neg_correct=neg_correct,\n",
    "                neg_count=neg_count,\n",
    "                **metrics_dict,\n",
    "            )\n",
    "        )\n",
    "        log.info(\n",
    "            (\"E{} {:8} {loss/pos:.4f} loss, \"\n",
    "                 + \"{correct/pos:-5.1f}% correct ({pos_correct:} of {pos_count:})\"\n",
    "            ).format(\n",
    "                epoch_ndx,\n",
    "                mode_str + '_pos',\n",
    "                pos_correct=pos_correct,\n",
    "                pos_count=pos_count,\n",
    "                **metrics_dict,\n",
    "            )\n",
    "        )\n",
    "        writer = getattr(self, mode_str + '_writer')\n",
    "\n",
    "        for key, value in metrics_dict.items():\n",
    "            writer.add_scalar(key, value, self.totalTrainingSamples_count)\n",
    "\n",
    "        writer.add_pr_curve(\n",
    "            'pr',\n",
    "            metrics_t[METRICS_LABEL_NDX],\n",
    "            metrics_t[METRICS_PRED_NDX],\n",
    "            self.totalTrainingSamples_count,\n",
    "        )\n",
    "\n",
    "        bins = [x/50.0 for x in range(51)]\n",
    "\n",
    "        negHist_mask = negLabel_mask & (metrics_t[METRICS_PRED_NDX] > 0.01)\n",
    "        posHist_mask = posLabel_mask & (metrics_t[METRICS_PRED_NDX] < 0.99)\n",
    "\n",
    "        if negHist_mask.any():\n",
    "            writer.add_histogram(\n",
    "                'is_neg',\n",
    "                metrics_t[METRICS_PRED_NDX, negHist_mask],\n",
    "                self.totalTrainingSamples_count,\n",
    "                bins=bins,\n",
    "            )\n",
    "        if posHist_mask.any():\n",
    "            writer.add_histogram(\n",
    "                'is_pos',\n",
    "                metrics_t[METRICS_PRED_NDX, posHist_mask],\n",
    "                self.totalTrainingSamples_count,\n",
    "                bins=bins,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet impl\n",
    "\n",
    "# From https://github.com/jvanvugt/pytorch-unet\n",
    "# https://raw.githubusercontent.com/jvanvugt/pytorch-unet/master/unet.py\n",
    "\n",
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2018 Joris\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# Adapted from https://discuss.pytorch.org/t/unet-implementation/426\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, n_classes=2, depth=5, wf=6, padding=False,\n",
    "                 batch_norm=False, up_mode='upconv'):\n",
    "        \"\"\"\n",
    "        Implementation of\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        (Ronneberger et al., 2015)\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "        Using the default arguments will yield the exact version used\n",
    "        in the original paper\n",
    "        Args:\n",
    "            in_channels (int): number of input channels\n",
    "            n_classes (int): number of output channels\n",
    "            depth (int): depth of the network\n",
    "            wf (int): number of filters in the first layer is 2**wf\n",
    "            padding (bool): if True, apply padding such that the input shape\n",
    "                            is the same as the output.\n",
    "                            This may introduce artifacts\n",
    "            batch_norm (bool): Use BatchNorm after layers with an\n",
    "                               activation function\n",
    "            up_mode (str): one of 'upconv' or 'upsample'.\n",
    "                           'upconv' will use transposed convolutions for\n",
    "                           learned upsampling.\n",
    "                           'upsample' will use bilinear upsampling.\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(UNetConvBlock(prev_channels, 2**(wf+i),\n",
    "                                                padding, batch_norm))\n",
    "            prev_channels = 2**(wf+i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(UNetUpBlock(prev_channels, 2**(wf+i), up_mode,\n",
    "                                            padding, batch_norm))\n",
    "            prev_channels = 2**(wf+i)\n",
    "\n",
    "        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path)-1:\n",
    "                blocks.append(x)\n",
    "                x = F.avg_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i-1])\n",
    "\n",
    "        return self.last(x)\n",
    "\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3,\n",
    "                               padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        # block.append(nn.LeakyReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3,\n",
    "                               padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        # block.append(nn.LeakyReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        if up_mode == 'upconv':\n",
    "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2,\n",
    "                                         stride=2)\n",
    "        elif up_mode == 'upsample':\n",
    "            self.up = nn.Sequential(nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                                    nn.Conv2d(in_size, out_size, kernel_size=1))\n",
    "\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[:, :, diff_y:(diff_y + target_size[0]), diff_x:(diff_x + target_size[1])]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.py\n",
    "\n",
    "import math\n",
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class UNetWrapper(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_batchnorm = nn.BatchNorm2d(kwargs['in_channels'])\n",
    "        self.unet = UNet(**kwargs)\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        init_set = {\n",
    "            nn.Conv2d,\n",
    "            nn.Conv3d,\n",
    "            nn.ConvTranspose2d,\n",
    "            nn.ConvTranspose3d,\n",
    "            nn.Linear,\n",
    "        }\n",
    "        for m in self.modules():\n",
    "            if type(m) in init_set:\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight.data, mode='fan_out', nonlinearity='relu', a=0\n",
    "                )\n",
    "                if m.bias is not None:\n",
    "                    fan_in, fan_out = \\\n",
    "                        nn.init._calculate_fan_in_and_fan_out(m.weight.data)\n",
    "                    bound = 1 / math.sqrt(fan_out)\n",
    "                    nn.init.normal_(m.bias, -bound, bound)\n",
    "\n",
    "        # nn.init.constant_(self.unet.last.bias, -4)\n",
    "        # nn.init.constant_(self.unet.last.bias, 4)\n",
    "\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        bn_output = self.input_batchnorm(input_batch)\n",
    "        un_output = self.unet(bn_output)\n",
    "        fn_output = self.final(un_output)\n",
    "        return fn_output\n",
    "\n",
    "class SegmentationAugmentation(nn.Module):\n",
    "    def __init__(\n",
    "            self, flip=None, offset=None, scale=None, rotate=None, noise=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.flip = flip\n",
    "        self.offset = offset\n",
    "        self.scale = scale\n",
    "        self.rotate = rotate\n",
    "        self.noise = noise\n",
    "\n",
    "    def forward(self, input_g, label_g):\n",
    "        transform_t = self._build2dTransformMatrix()\n",
    "        transform_t = transform_t.expand(input_g.shape[0], -1, -1)\n",
    "        transform_t = transform_t.to(input_g.device, torch.float32)\n",
    "        affine_t = F.affine_grid(transform_t[:,:2],\n",
    "                input_g.size(), align_corners=False)\n",
    "\n",
    "        augmented_input_g = F.grid_sample(input_g,\n",
    "                affine_t, padding_mode='border',\n",
    "                align_corners=False)\n",
    "        augmented_label_g = F.grid_sample(label_g.to(torch.float32),\n",
    "                affine_t, padding_mode='border',\n",
    "                align_corners=False)\n",
    "\n",
    "        if self.noise:\n",
    "            noise_t = torch.randn_like(augmented_input_g)\n",
    "            noise_t *= self.noise\n",
    "\n",
    "            augmented_input_g += noise_t\n",
    "\n",
    "        return augmented_input_g, augmented_label_g > 0.5\n",
    "\n",
    "    def _build2dTransformMatrix(self):\n",
    "        transform_t = torch.eye(3)\n",
    "\n",
    "        for i in range(2):\n",
    "            if self.flip:\n",
    "                if random.random() > 0.5:\n",
    "                    transform_t[i,i] *= -1\n",
    "\n",
    "            if self.offset:\n",
    "                offset_float = self.offset\n",
    "                random_float = (random.random() * 2 - 1)\n",
    "                transform_t[2,i] = offset_float * random_float\n",
    "\n",
    "            if self.scale:\n",
    "                scale_float = self.scale\n",
    "                random_float = (random.random() * 2 - 1)\n",
    "                transform_t[i,i] *= 1.0 + scale_float * random_float\n",
    "\n",
    "        if self.rotate:\n",
    "            angle_rad = random.random() * math.pi * 2\n",
    "            s = math.sin(angle_rad)\n",
    "            c = math.cos(angle_rad)\n",
    "\n",
    "            rotation_t = torch.tensor([\n",
    "                [c, -s, 0],\n",
    "                [s, c, 0],\n",
    "                [0, 0, 1]])\n",
    "\n",
    "            transform_t @= rotation_t\n",
    "\n",
    "        return transform_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark_seg.py\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import socket\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class BenchmarkLuna2dSegmentationDataset(TrainingLuna2dSegmentationDataset):\n",
    "    def __len__(self):\n",
    "        # return 500\n",
    "        return 5000\n",
    "        return 1000\n",
    "\n",
    "class LunaBenchmarkApp(LunaTrainingApp):\n",
    "    def initTrainDl(self):\n",
    "        train_ds = BenchmarkLuna2dSegmentationDataset(\n",
    "            val_stride=10,\n",
    "            isValSet_bool=False,\n",
    "            contextSlices_count=3,\n",
    "            # augmentation_dict=self.augmentation_dict,\n",
    "        )\n",
    "\n",
    "        batch_size = self.cli_args.batch_size\n",
    "        if self.use_cuda:\n",
    "            batch_size *= torch.cuda.device_count()\n",
    "\n",
    "        train_dl = DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=self.cli_args.num_workers,\n",
    "            pin_memory=self.use_cuda,\n",
    "        )\n",
    "\n",
    "        return train_dl\n",
    "\n",
    "    def main(self):\n",
    "        log.info(\"Starting {}, {}\".format(type(self).__name__, self.cli_args))\n",
    "\n",
    "        train_dl = self.initTrainDl()\n",
    "\n",
    "        for epoch_ndx in range(1, 2):\n",
    "            log.info(\"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "                epoch_ndx,\n",
    "                self.cli_args.epochs,\n",
    "                len(train_dl),\n",
    "                len([]),\n",
    "                self.cli_args.batch_size,\n",
    "                (torch.cuda.device_count() if self.use_cuda else 1),\n",
    "            ))\n",
    "\n",
    "            self.doTraining(epoch_ndx, train_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SegmentationMask, MaskTuple\n",
    "\n",
    "MaskTuple = namedtuple('MaskTuple', 'raw_dense_mask, dense_mask, body_mask, air_mask, raw_candidate_mask, candidate_mask, lung_mask, neg_mask, pos_mask')\n",
    "\n",
    "class SegmentationMask(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_list = nn.ModuleList([\n",
    "            self._make_circle_conv(radius) for radius in range(1, 8)\n",
    "        ])\n",
    "\n",
    "    def _make_circle_conv(self, radius):\n",
    "        diameter = 1 + radius * 2\n",
    "\n",
    "        a = torch.linspace(-1, 1, steps=diameter)**2\n",
    "        b = (a[None] + a[:, None])**0.5\n",
    "\n",
    "        circle_weights = (b <= 1.0).to(torch.float32)\n",
    "\n",
    "        conv = nn.Conv2d(1, 1, kernel_size=diameter, padding=radius, bias=False)\n",
    "        conv.weight.data.fill_(1)\n",
    "        conv.weight.data *= circle_weights / circle_weights.sum()\n",
    "\n",
    "        return conv\n",
    "\n",
    "\n",
    "    def erode(self, input_mask, radius, threshold=1):\n",
    "        conv = self.conv_list[radius - 1]\n",
    "        input_float = input_mask.to(torch.float32)\n",
    "        result = conv(input_float)\n",
    "\n",
    "        # log.debug(['erode in ', radius, threshold, input_float.min().item(), input_float.mean().item(), input_float.max().item()])\n",
    "        # log.debug(['erode out', radius, threshold, result.min().item(), result.mean().item(), result.max().item()])\n",
    "\n",
    "        return result >= threshold\n",
    "\n",
    "    def deposit(self, input_mask, radius, threshold=0):\n",
    "        conv = self.conv_list[radius - 1]\n",
    "        input_float = input_mask.to(torch.float32)\n",
    "        result = conv(input_float)\n",
    "\n",
    "        # log.debug(['deposit in ', radius, threshold, input_float.min().item(), input_float.mean().item(), input_float.max().item()])\n",
    "        # log.debug(['deposit out', radius, threshold, result.min().item(), result.mean().item(), result.max().item()])\n",
    "\n",
    "        return result > threshold\n",
    "\n",
    "    def fill_cavity(self, input_mask):\n",
    "        cumsum = input_mask.cumsum(-1)\n",
    "        filled_mask = (cumsum > 0)\n",
    "        filled_mask &= (cumsum < cumsum[..., -1:])\n",
    "        cumsum = input_mask.cumsum(-2)\n",
    "        filled_mask &= (cumsum > 0)\n",
    "        filled_mask &= (cumsum < cumsum[..., -1:, :])\n",
    "\n",
    "        return filled_mask\n",
    "\n",
    "\n",
    "    def forward(self, input_g, raw_pos_g):\n",
    "        gcc_g = input_g + 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # log.info(['gcc_g', gcc_g.min(), gcc_g.mean(), gcc_g.max()])\n",
    "\n",
    "            raw_dense_mask = gcc_g > 0.7\n",
    "            dense_mask = self.deposit(raw_dense_mask, 2)\n",
    "            dense_mask = self.erode(dense_mask, 6)\n",
    "            dense_mask = self.deposit(dense_mask, 4)\n",
    "\n",
    "            body_mask = self.fill_cavity(dense_mask)\n",
    "            air_mask = self.deposit(body_mask & ~dense_mask, 5)\n",
    "            air_mask = self.erode(air_mask, 6)\n",
    "\n",
    "            lung_mask = self.deposit(air_mask, 5)\n",
    "\n",
    "            raw_candidate_mask = gcc_g > 0.4\n",
    "            raw_candidate_mask &= air_mask\n",
    "            candidate_mask = self.erode(raw_candidate_mask, 1)\n",
    "            candidate_mask = self.deposit(candidate_mask, 1)\n",
    "\n",
    "            pos_mask = self.deposit((raw_pos_g > 0.5) & lung_mask, 2)\n",
    "\n",
    "            neg_mask = self.deposit(candidate_mask, 1)\n",
    "            neg_mask &= ~pos_mask\n",
    "            neg_mask &= lung_mask\n",
    "\n",
    "            # label_g = (neg_mask | pos_mask).to(torch.float32)\n",
    "            label_g = (pos_mask).to(torch.float32)\n",
    "            neg_g = neg_mask.to(torch.float32)\n",
    "            pos_g = pos_mask.to(torch.float32)\n",
    "\n",
    "        mask_dict = {\n",
    "            'raw_dense_mask': raw_dense_mask,\n",
    "            'dense_mask': dense_mask,\n",
    "            'body_mask': body_mask,\n",
    "            'air_mask': air_mask,\n",
    "            'raw_candidate_mask': raw_candidate_mask,\n",
    "            'candidate_mask': candidate_mask,\n",
    "            'lung_mask': lung_mask,\n",
    "            'neg_mask': neg_mask,\n",
    "            'pos_mask': pos_mask,\n",
    "        }\n",
    "\n",
    "        return label_g, neg_g, pos_g, lung_mask, mask_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis.py\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('nbagg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "clim=(-1000.0, 300)\n",
    "\n",
    "def findPositiveSamples(start_ndx=0, limit=100):\n",
    "    ds = LunaDataset(sortby_str='label_and_size')\n",
    "\n",
    "    positiveSample_list = []\n",
    "    for sample_tup in ds.candidateInfo_list:\n",
    "        if sample_tup.isNodule_bool:\n",
    "            print(len(positiveSample_list), sample_tup)\n",
    "            positiveSample_list.append(sample_tup)\n",
    "\n",
    "        if len(positiveSample_list) >= limit:\n",
    "            break\n",
    "\n",
    "    return positiveSample_list\n",
    "\n",
    "def showCandidate(series_uid, batch_ndx=None, **kwargs):\n",
    "    ds = LunaDataset(series_uid=series_uid, **kwargs)\n",
    "    pos_list = [i for i, x in enumerate(ds.candidateInfo_list) if x.isNodule_bool]\n",
    "\n",
    "    if batch_ndx is None:\n",
    "        if pos_list:\n",
    "            batch_ndx = pos_list[0]\n",
    "        else:\n",
    "            print(\"Warning: no positive samples found; using first negative sample.\")\n",
    "            batch_ndx = 0\n",
    "\n",
    "    ct = Ct(series_uid)\n",
    "    ct_t, pos_t, series_uid, center_irc = ds[batch_ndx]\n",
    "    ct_a = ct_t[0].numpy()\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 50))\n",
    "\n",
    "    group_list = [\n",
    "        [9, 11, 13],\n",
    "        [15, 16, 17],\n",
    "        [19, 21, 23],\n",
    "    ]\n",
    "\n",
    "    subplot = fig.add_subplot(len(group_list) + 2, 3, 1)\n",
    "    subplot.set_title('index {}'.format(int(center_irc.index)), fontsize=30)\n",
    "    for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "        label.set_fontsize(20)\n",
    "    plt.imshow(ct.hu_a[int(center_irc.index)], clim=clim, cmap='gray')\n",
    "\n",
    "    subplot = fig.add_subplot(len(group_list) + 2, 3, 2)\n",
    "    subplot.set_title('row {}'.format(int(center_irc.row)), fontsize=30)\n",
    "    for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "        label.set_fontsize(20)\n",
    "    plt.imshow(ct.hu_a[:,int(center_irc.row)], clim=clim, cmap='gray')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    subplot = fig.add_subplot(len(group_list) + 2, 3, 3)\n",
    "    subplot.set_title('col {}'.format(int(center_irc.col)), fontsize=30)\n",
    "    for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "        label.set_fontsize(20)\n",
    "    plt.imshow(ct.hu_a[:,:,int(center_irc.col)], clim=clim, cmap='gray')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    subplot = fig.add_subplot(len(group_list) + 2, 3, 4)\n",
    "    subplot.set_title('index {}'.format(int(center_irc.index)), fontsize=30)\n",
    "    for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "        label.set_fontsize(20)\n",
    "    plt.imshow(ct_a[ct_a.shape[0]//2], clim=clim, cmap='gray')\n",
    "\n",
    "    subplot = fig.add_subplot(len(group_list) + 2, 3, 5)\n",
    "    subplot.set_title('row {}'.format(int(center_irc.row)), fontsize=30)\n",
    "    for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "        label.set_fontsize(20)\n",
    "    plt.imshow(ct_a[:,ct_a.shape[1]//2], clim=clim, cmap='gray')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    subplot = fig.add_subplot(len(group_list) + 2, 3, 6)\n",
    "    subplot.set_title('col {}'.format(int(center_irc.col)), fontsize=30)\n",
    "    for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "        label.set_fontsize(20)\n",
    "    plt.imshow(ct_a[:,:,ct_a.shape[2]//2], clim=clim, cmap='gray')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "    for row, index_list in enumerate(group_list):\n",
    "        for col, index in enumerate(index_list):\n",
    "            subplot = fig.add_subplot(len(group_list) + 2, 3, row * 3 + col + 7)\n",
    "            subplot.set_title('slice {}'.format(index), fontsize=30)\n",
    "            for label in (subplot.get_xticklabels() + subplot.get_yticklabels()):\n",
    "                label.set_fontsize(20)\n",
    "            plt.imshow(ct_a[index], clim=clim, cmap='gray')\n",
    "\n",
    "\n",
    "    print(series_uid, batch_ndx, bool(pos_t[0]), pos_list)\n",
    "\n",
    "\n",
    "def build2dLungMask(series_uid, center_ndx):\n",
    "    mask_model = SegmentationMask().to('cuda')\n",
    "    ct = Ct(series_uid)\n",
    "\n",
    "    ct_g = torch.from_numpy(ct.hu_a[center_ndx].astype(np.float32)).unsqueeze(0).unsqueeze(0).to('cuda')\n",
    "    pos_g = torch.from_numpy(ct.positive_mask[center_ndx].astype(np.float32)).unsqueeze(0).unsqueeze(0).to('cuda')\n",
    "    input_g = ct_g / 1000\n",
    "\n",
    "    label_g, neg_g, pos_g, lung_mask, mask_dict = mask_model(input_g, pos_g)\n",
    "    mask_tup = MaskTuple(**mask_dict)\n",
    "\n",
    "    return mask_tup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepcache.py\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class LunaPrepCacheApp:\n",
    "    @classmethod\n",
    "    def __init__(self, sys_argv=None):\n",
    "        if sys_argv is None:\n",
    "            sys_argv = sys.argv[1:]\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--batch-size',\n",
    "            help='Batch size to use for training',\n",
    "            default=1024,\n",
    "            type=int,\n",
    "        )\n",
    "        parser.add_argument('--num-workers',\n",
    "            help='Number of worker processes for background data loading',\n",
    "            default=8,\n",
    "            type=int,\n",
    "        )\n",
    "\n",
    "        self.cli_args = parser.parse_args(sys_argv)\n",
    "\n",
    "    def main(self):\n",
    "        log.info(\"Starting {}, {}\".format(type(self).__name__, self.cli_args))\n",
    "\n",
    "        self.prep_dl = DataLoader(\n",
    "            PrepcacheLunaDataset(\n",
    "                # sortby_str='series_uid',\n",
    "            ),\n",
    "            batch_size=self.cli_args.batch_size,\n",
    "            num_workers=self.cli_args.num_workers,\n",
    "        )\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            self.prep_dl,\n",
    "            \"Stuffing cache\",\n",
    "            start_ndx=self.prep_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, batch_tup in batch_iter:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsets.py\n",
    "\n",
    "import copy\n",
    "import csv\n",
    "import functools\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import scipy.ndimage.morphology as morph\n",
    "\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "raw_cache = getCache('part2ch13_raw')\n",
    "\n",
    "MaskTuple = namedtuple('MaskTuple', 'raw_dense_mask, dense_mask, body_mask, air_mask, raw_candidate_mask, candidate_mask, lung_mask, neg_mask, pos_mask')\n",
    "\n",
    "CandidateInfoTuple = namedtuple('CandidateInfoTuple', 'isNodule_bool, hasAnnotation_bool, isMal_bool, diameter_mm, series_uid, center_xyz')\n",
    "\n",
    "\n",
    "@functools.lru_cache(1)\n",
    "def getCandidateInfoList(requireOnDisk_bool=True):\n",
    "    # We construct a set with all series_uids that are present on disk.\n",
    "    # This will let us use the data, even if we haven't downloaded all of\n",
    "    # the subsets yet.\n",
    "    mhd_list = glob.glob('../data/luna/subset*/*.mhd')\n",
    "    presentOnDisk_set = {os.path.split(p)[-1][:-4] for p in mhd_list}\n",
    "\n",
    "    candidateInfo_list = []\n",
    "    with open('../data/luna/segmentation/annotations_with_malignancy.csv', \"r\") as f:\n",
    "        for row in list(csv.reader(f))[1:]:\n",
    "            series_uid = row[0]\n",
    "            annotationCenter_xyz = tuple([float(x) for x in row[1:4]])\n",
    "            annotationDiameter_mm = float(row[4])\n",
    "            # TODO: there's a mismatch between the below dict and \n",
    "            # output of the notebook generating annotations_with_malignancy.csv\n",
    "            # row[5] is originally a float\n",
    "            isMal_bool = {'False': False, 'True': True}[str(bool(int(float(row[5]))))]\n",
    "\n",
    "            candidateInfo_list.append(\n",
    "                CandidateInfoTuple(\n",
    "                    True,\n",
    "                    True,\n",
    "                    isMal_bool,\n",
    "                    annotationDiameter_mm,\n",
    "                    series_uid,\n",
    "                    annotationCenter_xyz,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    with open('../data/luna/candidates.csv', \"r\") as f:\n",
    "        for row in list(csv.reader(f))[1:]:\n",
    "            series_uid = row[0]\n",
    "\n",
    "            if series_uid not in presentOnDisk_set and requireOnDisk_bool:\n",
    "                continue\n",
    "\n",
    "            isNodule_bool = bool(int(row[4]))\n",
    "            candidateCenter_xyz = tuple([float(x) for x in row[1:4]])\n",
    "\n",
    "            if not isNodule_bool:\n",
    "                candidateInfo_list.append(\n",
    "                    CandidateInfoTuple(\n",
    "                        False,\n",
    "                        False,\n",
    "                        False,\n",
    "                        0.0,\n",
    "                        series_uid,\n",
    "                        candidateCenter_xyz,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    candidateInfo_list.sort(reverse=True)\n",
    "    return candidateInfo_list\n",
    "\n",
    "\n",
    "@functools.lru_cache(1)\n",
    "def getCandidateInfoDict(requireOnDisk_bool=True):\n",
    "    candidateInfo_list = getCandidateInfoList(requireOnDisk_bool)\n",
    "    candidateInfo_dict = {}\n",
    "\n",
    "    for candidateInfo_tup in candidateInfo_list:\n",
    "        candidateInfo_dict.setdefault(candidateInfo_tup.series_uid,\n",
    "                                      []).append(candidateInfo_tup)\n",
    "\n",
    "    return candidateInfo_dict\n",
    "\n",
    "\n",
    "class Ct:\n",
    "    def __init__(self, series_uid):\n",
    "        mhd_path = glob.glob(\n",
    "            '../data/luna/subset*/{}.mhd'.format(series_uid)\n",
    "        )[0]\n",
    "\n",
    "        ct_mhd = sitk.ReadImage(mhd_path)\n",
    "        self.hu_a = np.array(sitk.GetArrayFromImage(ct_mhd), dtype=np.float32)\n",
    "\n",
    "        # CTs are natively expressed in https://en.wikipedia.org/wiki/Hounsfield_scale\n",
    "        # HU are scaled oddly, with 0 g/cc (air, approximately) being -1000 and 1 g/cc (water) being 0.\n",
    "\n",
    "        self.series_uid = series_uid\n",
    "\n",
    "        self.origin_xyz = XyzTuple(*ct_mhd.GetOrigin())\n",
    "        self.vxSize_xyz = XyzTuple(*ct_mhd.GetSpacing())\n",
    "        self.direction_a = np.array(ct_mhd.GetDirection()).reshape(3, 3)\n",
    "\n",
    "        candidateInfo_list = getCandidateInfoDict()[self.series_uid]\n",
    "\n",
    "        self.positiveInfo_list = [\n",
    "            candidate_tup\n",
    "            for candidate_tup in candidateInfo_list\n",
    "            if candidate_tup.isNodule_bool\n",
    "        ]\n",
    "        self.positive_mask = self.buildAnnotationMask(self.positiveInfo_list)\n",
    "        self.positive_indexes = (self.positive_mask.sum(axis=(1,2))\n",
    "                                 .nonzero()[0].tolist())\n",
    "\n",
    "    def buildAnnotationMask(self, positiveInfo_list, threshold_hu = -700):\n",
    "        boundingBox_a = np.zeros_like(self.hu_a, dtype=np.bool)\n",
    "\n",
    "        for candidateInfo_tup in positiveInfo_list:\n",
    "            center_irc = xyz2irc(\n",
    "                candidateInfo_tup.center_xyz,\n",
    "                self.origin_xyz,\n",
    "                self.vxSize_xyz,\n",
    "                self.direction_a,\n",
    "            )\n",
    "            ci = int(center_irc.index)\n",
    "            cr = int(center_irc.row)\n",
    "            cc = int(center_irc.col)\n",
    "\n",
    "            index_radius = 2\n",
    "            try:\n",
    "                while self.hu_a[ci + index_radius, cr, cc] > threshold_hu and \\\n",
    "                        self.hu_a[ci - index_radius, cr, cc] > threshold_hu:\n",
    "                    index_radius += 1\n",
    "            except IndexError:\n",
    "                index_radius -= 1\n",
    "\n",
    "            row_radius = 2\n",
    "            try:\n",
    "                while self.hu_a[ci, cr + row_radius, cc] > threshold_hu and \\\n",
    "                        self.hu_a[ci, cr - row_radius, cc] > threshold_hu:\n",
    "                    row_radius += 1\n",
    "            except IndexError:\n",
    "                row_radius -= 1\n",
    "\n",
    "            col_radius = 2\n",
    "            try:\n",
    "                while self.hu_a[ci, cr, cc + col_radius] > threshold_hu and \\\n",
    "                        self.hu_a[ci, cr, cc - col_radius] > threshold_hu:\n",
    "                    col_radius += 1\n",
    "            except IndexError:\n",
    "                col_radius -= 1\n",
    "\n",
    "            # assert index_radius > 0, repr([candidateInfo_tup.center_xyz, center_irc, self.hu_a[ci, cr, cc]])\n",
    "            # assert row_radius > 0\n",
    "            # assert col_radius > 0\n",
    "\n",
    "            boundingBox_a[\n",
    "                 ci - index_radius: ci + index_radius + 1,\n",
    "                 cr - row_radius: cr + row_radius + 1,\n",
    "                 cc - col_radius: cc + col_radius + 1] = True\n",
    "\n",
    "        mask_a = boundingBox_a & (self.hu_a > threshold_hu)\n",
    "\n",
    "        return mask_a\n",
    "\n",
    "    def getRawCandidate(self, center_xyz, width_irc):\n",
    "        center_irc = xyz2irc(center_xyz, self.origin_xyz, self.vxSize_xyz,\n",
    "                             self.direction_a)\n",
    "\n",
    "        slice_list = []\n",
    "        for axis, center_val in enumerate(center_irc):\n",
    "            start_ndx = int(round(center_val - width_irc[axis]/2))\n",
    "            end_ndx = int(start_ndx + width_irc[axis])\n",
    "\n",
    "            assert center_val >= 0 and center_val < self.hu_a.shape[axis], repr([self.series_uid, center_xyz, self.origin_xyz, self.vxSize_xyz, center_irc, axis])\n",
    "\n",
    "            if start_ndx < 0:\n",
    "                # log.warning(\"Crop outside of CT array: {} {}, center:{} shape:{} width:{}\".format(\n",
    "                #     self.series_uid, center_xyz, center_irc, self.hu_a.shape, width_irc))\n",
    "                start_ndx = 0\n",
    "                end_ndx = int(width_irc[axis])\n",
    "\n",
    "            if end_ndx > self.hu_a.shape[axis]:\n",
    "                # log.warning(\"Crop outside of CT array: {} {}, center:{} shape:{} width:{}\".format(\n",
    "                #     self.series_uid, center_xyz, center_irc, self.hu_a.shape, width_irc))\n",
    "                end_ndx = self.hu_a.shape[axis]\n",
    "                start_ndx = int(self.hu_a.shape[axis] - width_irc[axis])\n",
    "\n",
    "            slice_list.append(slice(start_ndx, end_ndx))\n",
    "\n",
    "        ct_chunk = self.hu_a[tuple(slice_list)]\n",
    "        pos_chunk = self.positive_mask[tuple(slice_list)]\n",
    "\n",
    "        return ct_chunk, pos_chunk, center_irc\n",
    "\n",
    "    \n",
    "@functools.lru_cache(1, typed=True)\n",
    "def getCt(series_uid):\n",
    "    return Ct(series_uid)\n",
    "\n",
    "\n",
    "@raw_cache.memoize(typed=True)\n",
    "def getCtRawCandidate(series_uid, center_xyz, width_irc):\n",
    "    ct = getCt(series_uid)\n",
    "    ct_chunk, pos_chunk, center_irc = ct.getRawCandidate(center_xyz,\n",
    "                                                         width_irc)\n",
    "    ct_chunk.clip(-1000, 1000, ct_chunk)\n",
    "    return ct_chunk, pos_chunk, center_irc\n",
    "\n",
    "\n",
    "@raw_cache.memoize(typed=True)\n",
    "def getCtSampleSize(series_uid):\n",
    "    ct = Ct(series_uid)\n",
    "    return int(ct.hu_a.shape[0]), ct.positive_indexes\n",
    "\n",
    "\n",
    "class TrainingLuna2dSegmentationDataset(Luna2dSegmentationDataset):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.ratio_int = 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return 300000\n",
    "\n",
    "    def shuffleSamples(self):\n",
    "        random.shuffle(self.candidateInfo_list)\n",
    "        random.shuffle(self.pos_list)\n",
    "\n",
    "    def __getitem__(self, ndx):\n",
    "        candidateInfo_tup = self.pos_list[ndx % len(self.pos_list)]\n",
    "        return self.getitem_trainingCrop(candidateInfo_tup)\n",
    "\n",
    "    def getitem_trainingCrop(self, candidateInfo_tup):\n",
    "        ct_a, pos_a, center_irc = getCtRawCandidate(\n",
    "            candidateInfo_tup.series_uid,\n",
    "            candidateInfo_tup.center_xyz,\n",
    "            (7, 96, 96),\n",
    "        )\n",
    "        pos_a = pos_a[3:4]\n",
    "\n",
    "        row_offset = random.randrange(0,32)\n",
    "        col_offset = random.randrange(0,32)\n",
    "        ct_t = torch.from_numpy(ct_a[:, row_offset:row_offset+64,\n",
    "                                     col_offset:col_offset+64]).to(torch.float32)\n",
    "        pos_t = torch.from_numpy(pos_a[:, row_offset:row_offset+64,\n",
    "                                       col_offset:col_offset+64]).to(torch.long)\n",
    "\n",
    "        slice_ndx = center_irc.index\n",
    "\n",
    "        return ct_t, pos_t, candidateInfo_tup.series_uid, slice_ndx\n",
    "\n",
    "    \n",
    "class PrepcacheLunaDataset(Dataset):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.candidateInfo_list = getCandidateInfoList()\n",
    "        self.pos_list = [nt for nt in self.candidateInfo_list if nt.isNodule_bool]\n",
    "\n",
    "        self.seen_set = set()\n",
    "        self.candidateInfo_list.sort(key=lambda x: x.series_uid)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.candidateInfo_list)\n",
    "\n",
    "    def __getitem__(self, ndx):\n",
    "        # candidate_t, pos_t, series_uid, center_t = super().__getitem__(ndx)\n",
    "\n",
    "        candidateInfo_tup = self.candidateInfo_list[ndx]\n",
    "        getCtRawCandidate(candidateInfo_tup.series_uid, candidateInfo_tup.center_xyz, (7, 96, 96))\n",
    "\n",
    "        series_uid = candidateInfo_tup.series_uid\n",
    "        if series_uid not in self.seen_set:\n",
    "            self.seen_set.add(series_uid)\n",
    "\n",
    "            getCtSampleSize(series_uid)\n",
    "            # ct = getCt(series_uid)\n",
    "            # for mask_ndx in ct.positive_indexes:\n",
    "            #     build2dLungMask(series_uid, mask_ndx)\n",
    "\n",
    "        return 0, 1 #candidate_t, pos_t, series_uid, center_t\n",
    "\n",
    "\n",
    "class TvTrainingLuna2dSegmentationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, isValSet_bool=False, val_stride=10, contextSlices_count=3):\n",
    "        assert contextSlices_count == 3\n",
    "        data = torch.load('./imgs_and_masks.pt')\n",
    "        suids = list(set(data['suids']))\n",
    "        trn_mask_suids = torch.arange(len(suids)) % val_stride < (val_stride - 1)\n",
    "        trn_suids = {s for i, s in zip(trn_mask_suids, suids) if i}\n",
    "        trn_mask = torch.tensor([(s in trn_suids) for s in data[\"suids\"]])\n",
    "        if not isValSet_bool:\n",
    "            self.imgs = data[\"imgs\"][trn_mask]\n",
    "            self.masks = data[\"masks\"][trn_mask]\n",
    "            self.suids = [s for s, i in zip(data[\"suids\"], trn_mask) if i]\n",
    "        else:\n",
    "            self.imgs = data[\"imgs\"][~trn_mask]\n",
    "            self.masks = data[\"masks\"][~trn_mask]\n",
    "            self.suids = [s for s, i in zip(data[\"suids\"], trn_mask) if not i]\n",
    "        # discard spurious hotspots and clamp bone\n",
    "        self.imgs.clamp_(-1000, 1000)\n",
    "        self.imgs /= 1000\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        oh, ow = torch.randint(0, 32, (2,))\n",
    "        sl = self.masks.size(1)//2\n",
    "        return self.imgs[i, :, oh: oh + 64, ow: ow + 64], 1, self.masks[i, sl: sl+1, oh: oh + 64, ow: ow + 64].to(torch.float32), self.suids[i], 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(app, *argv):\n",
    "    argv = list(argv)\n",
    "    log.info(\"Running: {}({!r}).main()\".format(app, argv))\n",
    "    \n",
    "    app_cls = app  # <2>\n",
    "    app_cls(argv).main()\n",
    "    \n",
    "    log.info(\"Finished: {}.{!r}).main()\".format(app, argv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training.py\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import hashlib\n",
    "import os\n",
    "import shutil\n",
    "import socket\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Used for computeClassificationLoss and logMetrics to index into metrics_t/metrics_a\n",
    "# METRICS_LABEL_NDX = 0\n",
    "METRICS_LOSS_NDX = 1\n",
    "# METRICS_FN_LOSS_NDX = 2\n",
    "# METRICS_ALL_LOSS_NDX = 3\n",
    "\n",
    "# METRICS_PTP_NDX = 4\n",
    "# METRICS_PFN_NDX = 5\n",
    "# METRICS_MFP_NDX = 6\n",
    "METRICS_TP_NDX = 7\n",
    "METRICS_FN_NDX = 8\n",
    "METRICS_FP_NDX = 9\n",
    "\n",
    "METRICS_SIZE = 10\n",
    "\n",
    "class SegmentationTrainingApp:\n",
    "    def __init__(self, sys_argv=None):\n",
    "        if sys_argv is None:\n",
    "            sys_argv = sys.argv[1:]\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        \n",
    "        parser.add_argument('-f', '--f-whatever',\n",
    "            help='Required to appease ipykernel',\n",
    "        )\n",
    "        \n",
    "        parser.add_argument('--batch-size',\n",
    "            help='Batch size to use for training',\n",
    "            default=16,\n",
    "            type=int,\n",
    "        )\n",
    "        parser.add_argument('--num-workers',\n",
    "            help='Number of worker processes for background data loading',\n",
    "            default=8,\n",
    "            type=int,\n",
    "        )\n",
    "        parser.add_argument('--epochs',\n",
    "            help='Number of epochs to train for',\n",
    "            default=1,\n",
    "            type=int,\n",
    "        )\n",
    "\n",
    "        parser.add_argument('--augmented',\n",
    "            help=\"Augment the training data.\",\n",
    "            action='store_true',\n",
    "            default=True,\n",
    "        )\n",
    "        parser.add_argument('--augment-flip',\n",
    "            help=\"Augment the training data by randomly flipping the data left-right, up-down, and front-back.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-offset',\n",
    "            help=\"Augment the training data by randomly offsetting the data slightly along the X and Y axes.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-scale',\n",
    "            help=\"Augment the training data by randomly increasing or decreasing the size of the candidate.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-rotate',\n",
    "            help=\"Augment the training data by randomly rotating the data around the head-foot axis.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "        parser.add_argument('--augment-noise',\n",
    "            help=\"Augment the training data by randomly adding noise to the data.\",\n",
    "            action='store_true',\n",
    "            default=False,\n",
    "        )\n",
    "\n",
    "        parser.add_argument('--tb-prefix',\n",
    "            default='p2ch13',\n",
    "            help=\"Data prefix to use for Tensorboard run. Defaults to chapter.\",\n",
    "        )\n",
    "\n",
    "        parser.add_argument('comment',\n",
    "            help=\"Comment suffix for Tensorboard run.\",\n",
    "            nargs='?',\n",
    "            default='none',\n",
    "        )\n",
    "\n",
    "        self.cli_args = parser.parse_args(sys_argv)\n",
    "        self.time_str = datetime.datetime.now().strftime('%Y-%m-%d_%H.%M.%S')\n",
    "        self.totalTrainingSamples_count = 0\n",
    "        self.trn_writer = None\n",
    "        self.val_writer = None\n",
    "\n",
    "        self.augmentation_dict = {}\n",
    "        if self.cli_args.augmented or self.cli_args.augment_flip:\n",
    "            self.augmentation_dict['flip'] = True\n",
    "        if self.cli_args.augmented or self.cli_args.augment_offset:\n",
    "            self.augmentation_dict['offset'] = 0.03\n",
    "        if self.cli_args.augmented or self.cli_args.augment_scale:\n",
    "            self.augmentation_dict['scale'] = 0.2\n",
    "        if self.cli_args.augmented or self.cli_args.augment_rotate:\n",
    "            self.augmentation_dict['rotate'] = True\n",
    "        if self.cli_args.augmented or self.cli_args.augment_noise:\n",
    "            self.augmentation_dict['noise'] = 25.0\n",
    "\n",
    "        self.use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda\" if self.use_cuda else \"cpu\")\n",
    "\n",
    "        self.segmentation_model, self.augmentation_model = self.initModel()\n",
    "        self.optimizer = self.initOptimizer()\n",
    "\n",
    "\n",
    "    def initModel(self):\n",
    "        segmentation_model = UNetWrapper(\n",
    "            in_channels=7,\n",
    "            n_classes=1,\n",
    "            depth=3,\n",
    "            wf=4,\n",
    "            padding=True,\n",
    "            batch_norm=True,\n",
    "            up_mode='upconv',\n",
    "        )\n",
    "\n",
    "        augmentation_model = SegmentationAugmentation(**self.augmentation_dict)\n",
    "\n",
    "        if self.use_cuda:\n",
    "            log.info(\"Using CUDA; {} devices.\".format(torch.cuda.device_count()))\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                segmentation_model = nn.DataParallel(segmentation_model)\n",
    "                augmentation_model = nn.DataParallel(augmentation_model)\n",
    "            segmentation_model = segmentation_model.to(self.device)\n",
    "            augmentation_model = augmentation_model.to(self.device)\n",
    "\n",
    "        return segmentation_model, augmentation_model\n",
    "\n",
    "    def initOptimizer(self):\n",
    "        return Adam(self.segmentation_model.parameters())\n",
    "        # return SGD(self.segmentation_model.parameters(), lr=0.001, momentum=0.99)\n",
    "\n",
    "\n",
    "    def initTrainDl(self):\n",
    "        train_ds = TrainingLuna2dSegmentationDataset(\n",
    "            val_stride=10,\n",
    "            isValSet_bool=False,\n",
    "            contextSlices_count=3,\n",
    "        )\n",
    "\n",
    "        batch_size = self.cli_args.batch_size\n",
    "        if self.use_cuda:\n",
    "            batch_size *= torch.cuda.device_count()\n",
    "\n",
    "        train_dl = DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=self.cli_args.num_workers,\n",
    "            pin_memory=self.use_cuda,\n",
    "        )\n",
    "\n",
    "        return train_dl\n",
    "\n",
    "    def initValDl(self):\n",
    "        val_ds = Luna2dSegmentationDataset(\n",
    "            val_stride=10,\n",
    "            isValSet_bool=True,\n",
    "            contextSlices_count=3,\n",
    "        )\n",
    "\n",
    "        batch_size = self.cli_args.batch_size\n",
    "        if self.use_cuda:\n",
    "            batch_size *= torch.cuda.device_count()\n",
    "\n",
    "        val_dl = DataLoader(\n",
    "            val_ds,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=self.cli_args.num_workers,\n",
    "            pin_memory=self.use_cuda,\n",
    "        )\n",
    "\n",
    "        return val_dl\n",
    "\n",
    "    def initTensorboardWriters(self):\n",
    "        if self.trn_writer is None:\n",
    "            log_dir = os.path.join('runs', self.cli_args.tb_prefix, self.time_str)\n",
    "\n",
    "            self.trn_writer = SummaryWriter(\n",
    "                log_dir=log_dir + '_trn_seg_' + self.cli_args.comment)\n",
    "            self.val_writer = SummaryWriter(\n",
    "                log_dir=log_dir + '_val_seg_' + self.cli_args.comment)\n",
    "\n",
    "    def main(self):\n",
    "        log.info(\"Starting {}, {}\".format(type(self).__name__, self.cli_args))\n",
    "\n",
    "        train_dl = self.initTrainDl()\n",
    "        val_dl = self.initValDl()\n",
    "\n",
    "        best_score = 0.0\n",
    "        self.validation_cadence = 5\n",
    "        for epoch_ndx in range(1, self.cli_args.epochs + 1):\n",
    "            log.info(\"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "                epoch_ndx,\n",
    "                self.cli_args.epochs,\n",
    "                len(train_dl),\n",
    "                len(val_dl),\n",
    "                self.cli_args.batch_size,\n",
    "                (torch.cuda.device_count() if self.use_cuda else 1),\n",
    "            ))\n",
    "\n",
    "            trnMetrics_t = self.doTraining(epoch_ndx, train_dl)\n",
    "            self.logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n",
    "\n",
    "            if epoch_ndx == 1 or epoch_ndx % self.validation_cadence == 0:\n",
    "                # if validation is wanted\n",
    "                valMetrics_t = self.doValidation(epoch_ndx, val_dl)\n",
    "                score = self.logMetrics(epoch_ndx, 'val', valMetrics_t)\n",
    "                best_score = max(score, best_score)\n",
    "\n",
    "                self.saveModel('seg', epoch_ndx, score == best_score)\n",
    "\n",
    "                self.logImages(epoch_ndx, 'trn', train_dl)\n",
    "                self.logImages(epoch_ndx, 'val', val_dl)\n",
    "\n",
    "        self.trn_writer.close()\n",
    "        self.val_writer.close()\n",
    "\n",
    "    def doTraining(self, epoch_ndx, train_dl):\n",
    "        trnMetrics_g = torch.zeros(METRICS_SIZE, len(train_dl.dataset), device=self.device)\n",
    "        self.segmentation_model.train()\n",
    "        train_dl.dataset.shuffleSamples()\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            train_dl,\n",
    "            \"E{} Training\".format(epoch_ndx),\n",
    "            start_ndx=train_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, batch_tup in batch_iter:\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            loss_var = self.computeBatchLoss(batch_ndx, batch_tup, train_dl.batch_size, trnMetrics_g)\n",
    "            loss_var.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "        self.totalTrainingSamples_count += trnMetrics_g.size(1)\n",
    "\n",
    "        return trnMetrics_g.to('cpu')\n",
    "\n",
    "    def doValidation(self, epoch_ndx, val_dl):\n",
    "        with torch.no_grad():\n",
    "            valMetrics_g = torch.zeros(METRICS_SIZE, len(val_dl.dataset), device=self.device)\n",
    "            self.segmentation_model.eval()\n",
    "\n",
    "            batch_iter = enumerateWithEstimate(\n",
    "                val_dl,\n",
    "                \"E{} Validation \".format(epoch_ndx),\n",
    "                start_ndx=val_dl.num_workers,\n",
    "            )\n",
    "            for batch_ndx, batch_tup in batch_iter:\n",
    "                self.computeBatchLoss(batch_ndx, batch_tup, val_dl.batch_size, valMetrics_g)\n",
    "\n",
    "        return valMetrics_g.to('cpu')\n",
    "\n",
    "    def computeBatchLoss(self, batch_ndx, batch_tup, batch_size, metrics_g,\n",
    "                         classificationThreshold=0.5):\n",
    "        input_t, label_t, series_list, _slice_ndx_list = batch_tup\n",
    "\n",
    "        input_g = input_t.to(self.device, non_blocking=True)\n",
    "        label_g = label_t.to(self.device, non_blocking=True)\n",
    "\n",
    "        if self.segmentation_model.training and self.augmentation_dict:\n",
    "            input_g, label_g = self.augmentation_model(input_g, label_g)\n",
    "\n",
    "        prediction_g = self.segmentation_model(input_g)\n",
    "\n",
    "        diceLoss_g = self.diceLoss(prediction_g, label_g)\n",
    "        fnLoss_g = self.diceLoss(prediction_g * label_g, label_g)\n",
    "\n",
    "        start_ndx = batch_ndx * batch_size\n",
    "        end_ndx = start_ndx + input_t.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictionBool_g = (prediction_g[:, 0:1]\n",
    "                                > classificationThreshold).to(torch.float32)\n",
    "\n",
    "            tp = (     predictionBool_g *  label_g).sum(dim=[1,2,3])\n",
    "            fn = ((1 - predictionBool_g) *  label_g).sum(dim=[1,2,3])\n",
    "            fp = (     predictionBool_g * (~label_g)).sum(dim=[1,2,3])\n",
    "\n",
    "            metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = diceLoss_g\n",
    "            metrics_g[METRICS_TP_NDX, start_ndx:end_ndx] = tp\n",
    "            metrics_g[METRICS_FN_NDX, start_ndx:end_ndx] = fn\n",
    "            metrics_g[METRICS_FP_NDX, start_ndx:end_ndx] = fp\n",
    "\n",
    "        return diceLoss_g.mean() + fnLoss_g.mean() * 8\n",
    "\n",
    "    def diceLoss(self, prediction_g, label_g, epsilon=1):\n",
    "        diceLabel_g = label_g.sum(dim=[1,2,3])\n",
    "        dicePrediction_g = prediction_g.sum(dim=[1,2,3])\n",
    "        diceCorrect_g = (prediction_g * label_g).sum(dim=[1,2,3])\n",
    "\n",
    "        diceRatio_g = (2 * diceCorrect_g + epsilon) \\\n",
    "            / (dicePrediction_g + diceLabel_g + epsilon)\n",
    "\n",
    "        return 1 - diceRatio_g\n",
    "\n",
    "\n",
    "    def logImages(self, epoch_ndx, mode_str, dl):\n",
    "        self.segmentation_model.eval()\n",
    "\n",
    "        images = sorted(dl.dataset.series_list)[:12]\n",
    "        for series_ndx, series_uid in enumerate(images):\n",
    "            ct = getCt(series_uid)\n",
    "\n",
    "            for slice_ndx in range(6):\n",
    "                ct_ndx = slice_ndx * (ct.hu_a.shape[0] - 1) // 5\n",
    "                sample_tup = dl.dataset.getitem_fullSlice(series_uid, ct_ndx)\n",
    "\n",
    "                ct_t, label_t, series_uid, ct_ndx = sample_tup\n",
    "\n",
    "                input_g = ct_t.to(self.device).unsqueeze(0)\n",
    "                label_g = pos_g = label_t.to(self.device).unsqueeze(0)\n",
    "\n",
    "                prediction_g = self.segmentation_model(input_g)[0]\n",
    "                prediction_a = prediction_g.to('cpu').detach().numpy()[0] > 0.5\n",
    "                label_a = label_g.cpu().numpy()[0][0] > 0.5\n",
    "\n",
    "                ct_t[:-1,:,:] /= 2000\n",
    "                ct_t[:-1,:,:] += 0.5\n",
    "\n",
    "                ctSlice_a = ct_t[dl.dataset.contextSlices_count].numpy()\n",
    "\n",
    "                image_a = np.zeros((512, 512, 3), dtype=np.float32)\n",
    "                image_a[:,:,:] = ctSlice_a.reshape((512,512,1))\n",
    "                image_a[:,:,0] += prediction_a & (1 - label_a)\n",
    "                image_a[:,:,0] += (1 - prediction_a) & label_a\n",
    "                image_a[:,:,1] += ((1 - prediction_a) & label_a) * 0.5\n",
    "\n",
    "                image_a[:,:,1] += prediction_a & label_a\n",
    "                image_a *= 0.5\n",
    "                image_a.clip(0, 1, image_a)\n",
    "\n",
    "                writer = getattr(self, mode_str + '_writer')\n",
    "                writer.add_image(\n",
    "                    f'{mode_str}/{series_ndx}_prediction_{slice_ndx}',\n",
    "                    image_a,\n",
    "                    self.totalTrainingSamples_count,\n",
    "                    dataformats='HWC',\n",
    "                )\n",
    "\n",
    "                if epoch_ndx == 1:\n",
    "                    image_a = np.zeros((512, 512, 3), dtype=np.float32)\n",
    "                    image_a[:,:,:] = ctSlice_a.reshape((512,512,1))\n",
    "                    # image_a[:,:,0] += (1 - label_a) & lung_a # Red\n",
    "                    image_a[:,:,1] += label_a  # Green\n",
    "                    # image_a[:,:,2] += neg_a  # Blue\n",
    "\n",
    "                    image_a *= 0.5\n",
    "                    image_a[image_a < 0] = 0\n",
    "                    image_a[image_a > 1] = 1\n",
    "                    writer.add_image(\n",
    "                        '{}/{}_label_{}'.format(\n",
    "                            mode_str,\n",
    "                            series_ndx,\n",
    "                            slice_ndx,\n",
    "                        ),\n",
    "                        image_a,\n",
    "                        self.totalTrainingSamples_count,\n",
    "                        dataformats='HWC',\n",
    "                    )\n",
    "                # This flush prevents TB from getting confused about which\n",
    "                # data item belongs where.\n",
    "                writer.flush()\n",
    "\n",
    "    def logMetrics(self, epoch_ndx, mode_str, metrics_t):\n",
    "        log.info(\"E{} {}\".format(\n",
    "            epoch_ndx,\n",
    "            type(self).__name__,\n",
    "        ))\n",
    "\n",
    "        metrics_a = metrics_t.detach().numpy()\n",
    "        sum_a = metrics_a.sum(axis=1)\n",
    "        assert np.isfinite(metrics_a).all()\n",
    "\n",
    "        allLabel_count = sum_a[METRICS_TP_NDX] + sum_a[METRICS_FN_NDX]\n",
    "\n",
    "        metrics_dict = {}\n",
    "        metrics_dict['loss/all'] = metrics_a[METRICS_LOSS_NDX].mean()\n",
    "\n",
    "        metrics_dict['percent_all/tp'] = \\\n",
    "            sum_a[METRICS_TP_NDX] / (allLabel_count or 1) * 100\n",
    "        metrics_dict['percent_all/fn'] = \\\n",
    "            sum_a[METRICS_FN_NDX] / (allLabel_count or 1) * 100\n",
    "        metrics_dict['percent_all/fp'] = \\\n",
    "            sum_a[METRICS_FP_NDX] / (allLabel_count or 1) * 100\n",
    "\n",
    "\n",
    "        precision = metrics_dict['pr/precision'] = sum_a[METRICS_TP_NDX] \\\n",
    "            / ((sum_a[METRICS_TP_NDX] + sum_a[METRICS_FP_NDX]) or 1)\n",
    "        recall    = metrics_dict['pr/recall']    = sum_a[METRICS_TP_NDX] \\\n",
    "            / ((sum_a[METRICS_TP_NDX] + sum_a[METRICS_FN_NDX]) or 1)\n",
    "\n",
    "        metrics_dict['pr/f1_score'] = 2 * (precision * recall) \\\n",
    "            / ((precision + recall) or 1)\n",
    "\n",
    "        log.info((\"E{} {:8} \"\n",
    "                 + \"{loss/all:.4f} loss, \"\n",
    "                 + \"{pr/precision:.4f} precision, \"\n",
    "                 + \"{pr/recall:.4f} recall, \"\n",
    "                 + \"{pr/f1_score:.4f} f1 score\"\n",
    "                  ).format(\n",
    "            epoch_ndx,\n",
    "            mode_str,\n",
    "            **metrics_dict,\n",
    "        ))\n",
    "        log.info((\"E{} {:8} \"\n",
    "                  + \"{loss/all:.4f} loss, \"\n",
    "                  + \"{percent_all/tp:-5.1f}% tp, {percent_all/fn:-5.1f}% fn, {percent_all/fp:-9.1f}% fp\"\n",
    "        ).format(\n",
    "            epoch_ndx,\n",
    "            mode_str + '_all',\n",
    "            **metrics_dict,\n",
    "        ))\n",
    "\n",
    "        self.initTensorboardWriters()\n",
    "        writer = getattr(self, mode_str + '_writer')\n",
    "\n",
    "        prefix_str = 'seg_'\n",
    "\n",
    "        for key, value in metrics_dict.items():\n",
    "            writer.add_scalar(prefix_str + key, value, self.totalTrainingSamples_count)\n",
    "\n",
    "        writer.flush()\n",
    "\n",
    "        score = metrics_dict['pr/recall']\n",
    "\n",
    "        return score\n",
    "\n",
    "    \n",
    "    def saveModel(self, type_str, epoch_ndx, isBest=False):\n",
    "        file_path = os.path.join(\n",
    "            'data-unversioned',\n",
    "            'part2',\n",
    "            'models',\n",
    "            self.cli_args.tb_prefix,\n",
    "            '{}_{}_{}.{}.state'.format(\n",
    "                type_str,\n",
    "                self.time_str,\n",
    "                self.cli_args.comment,\n",
    "                self.totalTrainingSamples_count,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        os.makedirs(os.path.dirname(file_path), mode=0o755, exist_ok=True)\n",
    "\n",
    "        model = self.segmentation_model\n",
    "        if isinstance(model, torch.nn.DataParallel):\n",
    "            model = model.module\n",
    "\n",
    "        state = {\n",
    "            'sys_argv': sys.argv,\n",
    "            'time': str(datetime.datetime.now()),\n",
    "            'model_state': model.state_dict(),\n",
    "            'model_name': type(model).__name__,\n",
    "            'optimizer_state' : self.optimizer.state_dict(),\n",
    "            'optimizer_name': type(self.optimizer).__name__,\n",
    "            'epoch': epoch_ndx,\n",
    "            'totalTrainingSamples_count': self.totalTrainingSamples_count,\n",
    "        }\n",
    "        torch.save(state, file_path)\n",
    "\n",
    "        log.info(\"Saved model params to {}\".format(file_path))\n",
    "\n",
    "        if isBest:\n",
    "            best_path = os.path.join(\n",
    "                'data-unversioned', 'part2', 'models',\n",
    "                self.cli_args.tb_prefix,\n",
    "                f'{type_str}_{self.time_str}_{self.cli_args.comment}.best.state')\n",
    "            shutil.copyfile(file_path, best_path)\n",
    "\n",
    "            log.info(\"Saved model params to {}\".format(best_path))\n",
    "\n",
    "        with open(file_path, 'rb') as f:\n",
    "            log.info(\"SHA1: \" + hashlib.sha1(f.read()).hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E1 Training ----/18750, starting\n",
      "E1 Training ----/18750, done at 2021-01-10 14:08:45\n",
      "E1 Validation  ----/71, starting\n",
      "E1 Validation  ----/71, done at 2021-01-10 14:09:04\n",
      "E2 Training ----/18750, starting\n",
      "E2 Training ----/18750, done at 2021-01-10 14:15:27\n",
      "E3 Training ----/18750, starting\n",
      "E3 Training ----/18750, done at 2021-01-10 14:21:12\n",
      "E4 Training ----/18750, starting\n",
      "E4 Training ----/18750, done at 2021-01-10 14:26:56\n",
      "E5 Training ----/18750, starting\n",
      "E5 Training ----/18750, done at 2021-01-10 14:32:41\n",
      "E5 Validation  ----/71, starting\n",
      "E5 Validation  ----/71, done at 2021-01-10 14:32:58\n",
      "E6 Training ----/18750, starting\n",
      "E6 Training ----/18750, done at 2021-01-10 14:39:08\n",
      "E7 Training ----/18750, starting\n",
      "E7 Training ----/18750, done at 2021-01-10 14:44:53\n",
      "E8 Training ----/18750, starting\n",
      "E8 Training ----/18750, done at 2021-01-10 14:50:38\n",
      "E9 Training ----/18750, starting\n",
      "E9 Training ----/18750, done at 2021-01-10 14:56:24\n",
      "E10 Training ----/18750, starting\n",
      "E10 Training ----/18750, done at 2021-01-10 15:02:11\n",
      "E10 Validation  ----/71, starting\n",
      "E10 Validation  ----/71, done at 2021-01-10 15:02:30\n"
     ]
    }
   ],
   "source": [
    "run(SegmentationTrainingApp, \"--epochs=10\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvpart2",
   "language": "python",
   "name": "venvpart2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
