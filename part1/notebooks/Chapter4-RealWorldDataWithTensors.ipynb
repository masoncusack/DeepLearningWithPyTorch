{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to represent different types of data with tensors. Types covered: images, tabular, time series, text.\n",
    "\n",
    "## Working with images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 855, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "img_arr = imageio.imread(\"../data/p1ch4/image-dog/bobby.jpg\")\n",
    "img_arr.shape # H x W x C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1280, 855])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2, 0, 1) # Permute to fit C x H x W dimension ordering\n",
    "out.shape\n",
    "\n",
    "# Note: permute doesn't create a new image, but alters the size and stride information at the level\n",
    "# of the original tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To creat a dataset of multiple images to use as input for our neural networks, we store the images\n",
    "in a batch along the first dimension to obtain an N x C x H x W tensor.\n",
    "\"\"\"\n",
    "\n",
    "# An efficient way to create a batch is pre-allocation followed by loading from a directory\n",
    "\n",
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '../data/p1ch4/image-cats/'\n",
    "filenames = [name for name in os.listdir(data_dir)\n",
    "             if os.path.splitext(name)[-1] == \".png\"] # Condition ensures images used are of a desired format.\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "\n",
    "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    img_t = img_t[:3]\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 90,  91,  93,  ..., 191, 191, 191],\n",
       "         [ 91,  91,  93,  ..., 191, 191, 191],\n",
       "         [ 91,  92,  93,  ..., 192, 192, 192],\n",
       "         ...,\n",
       "         [206, 210, 213,  ..., 220, 219, 218],\n",
       "         [209, 214, 214,  ..., 221, 220, 219],\n",
       "         [212, 212, 212,  ..., 219, 218, 218]],\n",
       "\n",
       "        [[108, 109, 111,  ..., 201, 201, 201],\n",
       "         [109, 109, 111,  ..., 201, 201, 201],\n",
       "         [109, 110, 111,  ..., 202, 202, 202],\n",
       "         ...,\n",
       "         [198, 202, 205,  ..., 214, 213, 212],\n",
       "         [201, 206, 206,  ..., 213, 212, 211],\n",
       "         [204, 204, 204,  ..., 211, 210, 210]],\n",
       "\n",
       "        [[120, 121, 123,  ..., 210, 210, 210],\n",
       "         [121, 121, 123,  ..., 210, 210, 210],\n",
       "         [121, 122, 123,  ..., 211, 211, 211],\n",
       "         ...,\n",
       "         [198, 202, 205,  ..., 214, 213, 212],\n",
       "         [201, 206, 206,  ..., 213, 212, 211],\n",
       "         [204, 204, 204,  ..., 211, 210, 210]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3529, 0.3569, 0.3647,  ..., 0.7490, 0.7490, 0.7490],\n",
       "         [0.3569, 0.3569, 0.3647,  ..., 0.7490, 0.7490, 0.7490],\n",
       "         [0.3569, 0.3608, 0.3647,  ..., 0.7529, 0.7529, 0.7529],\n",
       "         ...,\n",
       "         [0.8078, 0.8235, 0.8353,  ..., 0.8627, 0.8588, 0.8549],\n",
       "         [0.8196, 0.8392, 0.8392,  ..., 0.8667, 0.8627, 0.8588],\n",
       "         [0.8314, 0.8314, 0.8314,  ..., 0.8588, 0.8549, 0.8549]],\n",
       "\n",
       "        [[0.4235, 0.4275, 0.4353,  ..., 0.7882, 0.7882, 0.7882],\n",
       "         [0.4275, 0.4275, 0.4353,  ..., 0.7882, 0.7882, 0.7882],\n",
       "         [0.4275, 0.4314, 0.4353,  ..., 0.7922, 0.7922, 0.7922],\n",
       "         ...,\n",
       "         [0.7765, 0.7922, 0.8039,  ..., 0.8392, 0.8353, 0.8314],\n",
       "         [0.7882, 0.8078, 0.8078,  ..., 0.8353, 0.8314, 0.8275],\n",
       "         [0.8000, 0.8000, 0.8000,  ..., 0.8275, 0.8235, 0.8235]],\n",
       "\n",
       "        [[0.4706, 0.4745, 0.4824,  ..., 0.8235, 0.8235, 0.8235],\n",
       "         [0.4745, 0.4745, 0.4824,  ..., 0.8235, 0.8235, 0.8235],\n",
       "         [0.4745, 0.4784, 0.4824,  ..., 0.8275, 0.8275, 0.8275],\n",
       "         ...,\n",
       "         [0.7765, 0.7922, 0.8039,  ..., 0.8392, 0.8353, 0.8314],\n",
       "         [0.7882, 0.8078, 0.8078,  ..., 0.8353, 0.8314, 0.8275],\n",
       "         [0.8000, 0.8000, 0.8000,  ..., 0.8275, 0.8235, 0.8235]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best training performance is observed when input data values fall in the ranges [0, 1] or [-1, 1]\n",
    "\n",
    "batch = batch.float()\n",
    "batch /= 255.0\n",
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "May also want to compute the mean sand stdev of the input data and scale it\n",
    "so that the output has zero mean and unit stdev across each channel\n",
    "\n",
    "Torch provides functions for calculating these for tensors\n",
    "\"\"\"\n",
    "\n",
    "n_channels = batch.shape[1]\n",
    "for c in range(n_channels):\n",
    "    mean = torch.mean(batch[:, c])\n",
    "    std = torch.std(batch[:, c])\n",
    "    batch[:, c] = (batch[:, c] - mean) / std\n",
    "    \n",
    "# NOTE: it's good practice to compute the mean and stdev on all training data in \n",
    "# advance and then subtract nad divide by these fixed, precomputed quanities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D images\n",
    "\n",
    "In some domains, sequences of images are stacked along the head-to-foot axis. E.g. the slices in CT scans.\n",
    "\n",
    "By stacking individual 2D slices into a 3D tensor, we can built _volumetric data_ representing the 3D anatomy of a subject. Storing volumetric data is just like storing image data, except that an extra dimension, _depth_, comes after the standard channel dimension, resulting in a 5D tensor of shape `N x C x D x H x W`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DICOM (examining files): 1/99 files (1.0%3/99 files (3.0%6/99 files (6.1%9/99 files (9.1%12/99 files (12.1%16/99 files (16.2%20/99 files (20.2%26/99 files (26.3%33/99 files (33.3%40/99 files (40.4%46/99 files (46.5%56/99 files (56.6%68/99 files (68.7%83/99 files (83.8%98/99 files (99.0%99/99 files (100.0%)\n",
      "  Found 1 correct series.\n",
      "Reading DICOM (loading data): 27/99  (27.363/99  (63.699/99  (100.0%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99, 512, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the specialised format\n",
    "# Volumetric data can be downloaded from: https://github.com/deep-learning-with-pytorch/dlwpt-code/tree/master/data/p1ch4/volumetric-dicom/2-LUNG%203.0%20%20B70f-04083\n",
    "\n",
    "import imageio\n",
    "dir_path = \"../data/p1ch4/volumetric-dicom/2-LUNG 3.0  B70f-04083\"\n",
    "vol_arr = imageio.volread(dir_path, 'DICOM')\n",
    "vol_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.044</td>\n",
       "      <td>28.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "5            8.1              0.28         0.40             6.9      0.050   \n",
       "6            6.2              0.32         0.16             7.0      0.045   \n",
       "7            7.0              0.27         0.36            20.7      0.045   \n",
       "8            6.3              0.30         0.34             1.6      0.049   \n",
       "9            8.1              0.22         0.43             1.5      0.044   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "5                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "6                 30.0                 136.0   0.9949  3.18       0.47   \n",
       "7                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "8                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "9                 28.0                 129.0   0.9938  3.22       0.45   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  \n",
       "5     10.1        6  \n",
       "6      9.6        6  \n",
       "7      8.8        6  \n",
       "8      9.5        6  \n",
       "9     11.0        6  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As pandas is recommended, I used pandas instead of numpy (which is used in the book),\n",
    "# as I need to get comfortable with it.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "wine_path = \"../data/p1ch4/tabular-wine/winequality-white.csv\"\n",
    "wineq_df = pd.read_csv(wine_path, delimiter=\";\")\n",
    "col_list = list(wineq_df.columns)\n",
    "wineq_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12),\n",
       " Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "        'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "        'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq_df.shape, wineq_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wineq_df.values)\n",
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7.0000,  0.2700,  0.3600,  ...,  3.0000,  0.4500,  8.8000],\n",
       "         [ 6.3000,  0.3000,  0.3400,  ...,  3.3000,  0.4900,  9.5000],\n",
       "         [ 8.1000,  0.2800,  0.4000,  ...,  3.2600,  0.4400, 10.1000],\n",
       "         ...,\n",
       "         [ 6.5000,  0.2400,  0.1900,  ...,  2.9900,  0.4600,  9.4000],\n",
       "         [ 5.5000,  0.2900,  0.3000,  ...,  3.3400,  0.3800, 12.8000],\n",
       "         [ 6.0000,  0.2100,  0.3800,  ...,  3.2600,  0.3200, 11.8000]],\n",
       "        dtype=torch.float64),\n",
       " torch.Size([4898, 11]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Choices with the \"quality\" score:\n",
    "\n",
    "1. Treat as a continuous variable, keep it as a real number, perform a regression task\n",
    "    (by definition real number prediction)\n",
    "2. Treat it as a label and try to guess the label from the chemical analysis in a classification task\n",
    "\n",
    "Regardless, we separate this out so it's not an input which influences model training,\n",
    "as this is what we're trying to predict.\n",
    "\"\"\"\n",
    "\n",
    "data = wineq[:, :-1] # Selects all rows and all columns except the last\n",
    "data, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 6., 6.,  ..., 6., 7., 6.], dtype=torch.float64),\n",
       " torch.Size([4898]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = wineq[:, -1] # Selects all rows and the last column\n",
    "target, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 6, 6,  ..., 6, 7, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert targets to integer vector of scores, which we then one hot encode (target.unsqueeze() below)\n",
    "# We could also just keep it like this\n",
    "\n",
    "target = wineq[:, -1].long()\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now treat then targets as an integer vector of scores, or one-hot encode.\n",
    "# One-hot encoding has the advantage of not implying (and thus embedding) ordering or distance between targets\n",
    "\n",
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1.0) # trailing underscore == in place operation\n",
    "target_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What `scatter_` does:\n",
    "\n",
    "Take the index of the target label (== the score or 'target' itself in the case of this one-hot encoding),\n",
    "use it as the column index (hence first argument dim=1), to set the value 1.0.\n",
    "\n",
    "The result is a one-hot encoded tensor.\n",
    "\n",
    "Note: unsqueeze is necessary because the index tensor is required to have the same number of dimensions\n",
    "as the tensor we scatter into. Unsqueeze just adds a singleton dimension for this purpose. It doesn't\n",
    "affect the existing values of the index tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtaining mean and standard deviations for each column\n",
    "\n",
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0) # variance\n",
    "data_var\n",
    "\n",
    "# At this point we can normalize the data by subtracing the mean and dividing by the stdev, which\n",
    "# helps the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7208e-01, -8.1762e-02,  2.1326e-01,  ..., -1.2468e+00,\n",
       "         -3.4915e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  4.7996e-02,  ...,  7.3995e-01,\n",
       "          1.3417e-03, -8.2419e-01],\n",
       "        [ 1.4756e+00,  1.7450e-02,  5.4378e-01,  ...,  4.7505e-01,\n",
       "         -4.3677e-01, -3.3663e-01],\n",
       "        ...,\n",
       "        [-4.2043e-01, -3.7940e-01, -1.1915e+00,  ..., -1.3130e+00,\n",
       "         -2.6153e-01, -9.0545e-01],\n",
       "        [-1.6054e+00,  1.1666e-01, -2.8253e-01,  ...,  1.0049e+00,\n",
       "         -9.6251e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  3.7852e-01,  ...,  4.7505e-01,\n",
       "         -1.4882e+00,  1.0448e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalising data\n",
    "data_normalised = (data - data_mean) / torch.sqrt(data_var)\n",
    "data_normalised\n",
    "\n",
    "# NOTE: you can also use torch.std to get the stdev immediately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(20))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find wines with scores <= 3\n",
    "bad_indexes = target <= 3\n",
    "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 11])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With advanced indexing, we can use this 20-element bool tensor to index the data tensor.\n",
    "# This works like filtering -> give me only items corresponding to True in the indexing tensor.\n",
    "\n",
    "bad_data = data[bad_indexes] # super neat\n",
    "bad_data.shape\n",
    "\n",
    "# So, done quickly... bad_data = data[target <= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 fixed acidity          7.60   6.89   6.73\n",
      " 1 volatile acidity       0.33   0.28   0.27\n",
      " 2 citric acid            0.34   0.34   0.33\n",
      " 3 residual sugar         6.39   6.71   5.26\n",
      " 4 chlorides              0.05   0.05   0.04\n",
      " 5 free sulfur dioxide   53.33  35.42  34.55\n",
      " 6 total sulfur dioxide 170.60 141.83 125.25\n",
      " 7 density                0.99   0.99   0.99\n",
      " 8 pH                     3.19   3.18   3.22\n",
      " 9 sulphates              0.47   0.49   0.50\n",
      "10 alcohol               10.35  10.26  11.42\n"
     ]
    }
   ],
   "source": [
    "# Get information about wine grouped into good, middle, and bad categories\n",
    "\n",
    "bad_data = data[target <= 3]\n",
    "mid_data = data[(target > 3) & (target < 7)]\n",
    "good_data = data[target >= 7]\n",
    "\n",
    "bad_mean = torch.mean(bad_data, dim=0)\n",
    "mid_mean = torch.mean(mid_data, dim=0)\n",
    "good_mean = torch.mean(good_data, dim=0)\n",
    "\n",
    "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
    "    print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(2727))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bad wines seem to have a higher total sulfur dioxide.\n",
    "# A threshold on this could be a crude criteron for discriminating good wines\n",
    "\n",
    "total_sulfur_threshold = 141.83\n",
    "total_sulfur_data = data[:, 6] # All rows of column 6.\n",
    "# Interesting that rows and columns are inverted to the way we index dimensions (dim=0 is column).\n",
    "\n",
    "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold)\n",
    "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(3258))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_indexes = target > 5\n",
    "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()\n",
    "# There are about 500 more good wines than the threshoold predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2018, 0.74000733406674, 0.6193984039287906)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How well did we do relative to the actual ranking?\n",
    "\n",
    "n_matches = torch.sum(actual_indexes & predicted_indexes).item() # .item() removes number from tensor result\n",
    "n_predicted = torch.sum(predicted_indexes).item()\n",
    "n_actual = torch.sum(actual_indexes).item()\n",
    "\n",
    "n_matches, n_matches / n_predicted, n_matches / n_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 2000 scores predicted correctly, 74% accuracy of good wine prediction, 61% of actual good wines predicted.\n",
    "\n",
    "Slightly better than random, but ultimately we know that multiple variables in fact contribute to wine quality, and their relationship with the outcome is likely more complicated than a threshold on a single value can account for.\n",
    "\n",
    "A simple neural network could overcome this limitation (to come later.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to the Washington, D.C. bike-sharing system dataset.\n",
    "\n",
    "This reports the hourly count of rental bikes in 2011 - 2012 in the Capital Bikeshare syustem, along with weather and seasonal information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 3.0000e+00, 1.3000e+01,\n",
       "         1.6000e+01],\n",
       "        [2.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.0000e+00, 3.2000e+01,\n",
       "         4.0000e+01],\n",
       "        [3.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 5.0000e+00, 2.7000e+01,\n",
       "         3.2000e+01],\n",
       "        ...,\n",
       "        [1.7377e+04, 3.1000e+01, 1.0000e+00,  ..., 7.0000e+00, 8.3000e+01,\n",
       "         9.0000e+01],\n",
       "        [1.7378e+04, 3.1000e+01, 1.0000e+00,  ..., 1.3000e+01, 4.8000e+01,\n",
       "         6.1000e+01],\n",
       "        [1.7379e+04, 3.1000e+01, 1.0000e+00,  ..., 1.2000e+01, 3.7000e+01,\n",
       "         4.9000e+01]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "bikes_numpy = np.loadtxt(\n",
    "    \"../data/p1ch4/bike-sharing-dataset/hour-fixed.csv\",\n",
    "    dtype=np.float32,\n",
    "    delimiter=\",\",\n",
    "    skiprows=1,\n",
    "    # Convert date strings to numbers corresponding to the day of the month in column 1\n",
    "    converters={1: lambda x: float(x[8:10])}\n",
    ")\n",
    "\n",
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every **hour**, the dataset reports the following variables:\n",
    "\n",
    "- Index of record: instant\n",
    "- Day of month: day\n",
    "- Season: season (1: spring, 2: summer, 3: fall, 4: winter)\n",
    "- Year: yr (0: 2011, 1: 2012)\n",
    "- Month: mnth (1 to 12)\n",
    "- Hour: hr (0 to 23)\n",
    "- Holiday status: holiday\n",
    "- Day of the week: weekday\n",
    "- Working day status: workingday\n",
    "- Weather situation: weathersit (1: clear, 2:mist, 3: light rain/snow, 4: heavy rain/snow)\n",
    "- Temperature in °C: temp\n",
    "- Perceived temperature in °C: atemp\n",
    "- Humidity: hum\n",
    "- Wind speed: windspeed\n",
    "- Number of casual (non-registered) users: casual\n",
    "- Number of registered users: registered\n",
    "- Count of rental bikes: cnt\n",
    "\n",
    "Rows represent successive time-points: this is the dimension along which they are ordered. Ordering provides an opporutnity to exploit causal temporal relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17520, 17]), (17, 1))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shaping the data into 24-hour chunks (time periods). 24-hour is chosen based on the size of the dataset.\n",
    "# Result will be daily sequences of ride counts and other exogenous variables.\n",
    "# torch.sort would order appropriately if not already\n",
    "\n",
    "bikes.shape, bikes.stride() # 17520 hours, 17 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 24, 17]), (408, 17, 1))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the data to have 3 axes - day, hour, then 17 columns\n",
    "\n",
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
    "daily_bikes.shape, daily_bikes.stride()\n",
    "# What's left: N sequences of L hours in a day, for C channels. (C dimension \"Channels\" is the columns in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: view changes the way the tensor looks at the same data as contained in storage. It returns a new tensor that changes the number of dimensions and striding information, without changing the storage. It's therefore a zero-cost rearranging of a tensor.\n",
    "\n",
    "We have to provide the shape of the new tensor to view. -1 is used as a placeholder for \"however many indexes are left, given the other dimensions and the orignal number of elements.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 17, 24]), (408, 1, 17))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For N x C x L ordering, transpose\n",
    "daily_bikes = daily_bikes.transpose(1, 2)\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weather situation variable is ordinal: 1 for good weather, 4 for worst. Treating it as categorical will require one-hot encoding. For first day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_day = bikes[:24].long()\n",
    "weather_onehot = torch.zeros(first_day.shape[0], 4)\n",
    "first_day[:, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scatter ones into the matrix according to the corresponding level at each row.\n",
    "\n",
    "weather_onehot.scatter_(\n",
    "    dim=1,\n",
    "    index=first_day[:,9].unsqueeze(1).long() - 1,\n",
    "    value=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
       "          0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
       "         16.0000,  1.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now concatenate the matrix to the original dataset\n",
    "torch.cat((bikes[:24], weather_onehot), 1)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternative\n",
    "\n",
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4, daily_bikes.shape[2])\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scatter_() received an invalid combination of arguments - got (int, Tensor, int, float), but expected one of:\n * (int dim, Tensor index, Tensor src)\n * (int dim, Tensor index, Number value)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-c1efde83fee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdaily_weather_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaily_bikes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdaily_weather_onehot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: scatter_() received an invalid combination of arguments - got (int, Tensor, int, float), but expected one of:\n * (int dim, Tensor index, Tensor src)\n * (int dim, Tensor index, Number value)\n"
     ]
    }
   ],
   "source": [
    "daily_weather_onehot.scatter_(1, daily_bikes[:, 9, :].long().unsqueeze(1), - 1, 1.0)\n",
    "daily_weather_onehot.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvpart1",
   "language": "python",
   "name": "venvpart1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
